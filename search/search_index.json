{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"databind <p>The <code>databind</code> package provides a (de)serialization framework that understands most native Python types as well as dataclasses, as well as an implementation for serialize to/from JSON-like nested data structures.</p> <p>Databind is intended mostly for flexible and easy to use configuration loading. It does not try achieve high-performance; you should look towards e.g. mashumaro for this usecase.</p>"},{"location":"#example","title":"Example","text":"<pre><code>@dataclass\nclass Server:\n    host: str\n    port: int\n\n@dataclass\nclass Config:\n    server: Server\n\nfrom databind.json import dump, load\n\ndict_payload = {\"server\": {\"host\": \"localhost\", \"port\": 8080}}\nloaded = Config(server=Server(host=\"localhost\", port=8080))\n\nassert load(dict_payload, Config) == loaded\nassert dump(loaded, Config) == dict_payload\n</code></pre>"},{"location":"#features","title":"Features \u2728","text":"<ul> <li>Support for a plethora of builtin types, including <code>Enum</code>, <code>Decimal</code>, <code>UUID</code>, <code>Path</code>, <code>datetime</code>, <code>date</code>,   <code>time</code>, <code>timedelta</code></li> <li>Support for multiple union serialization modes (nested, flat, keyed, <code>typing.Literal</code>)</li> <li>Support for generic types, e.g. <code>load([{\"name\": \"Jane Doe\"}], list[Person])</code></li> <li>Support for new-style type hints in older Python versions when using forward refererences (strings or   <code>__future__.annotations</code>) thanks to typeapi<ul> <li>PEP 604 - Allow writing union types as X | Y</li> <li>PEP585 - Type Hinting Generics in Standard Collections)</li> </ul> </li> <li>Support for customized serialization and deserialization of types</li> <li>Support for flattening fields of a nested dataclass or collecting remaining fields in a <code>dict</code></li> <li>Full runtime type checking during serialization</li> <li>Use \"settings\" to customize serialization behaviour<ul> <li>As global settings per <code>load()</code>/<code>dump()</code> call: <code>load(..., settings=[ExtraKeys(True)])</code></li> <li>As class-level settings using a decorator: <code>@Union(style=Union.FLAT)</code> or <code>@ExtraKeys(True)</code></li> <li>As type-hint level settings using <code>typing.Annotated</code> (or <code>typing_extensions.Annotated</code>):   <code>full_name: Annotated[str, Alias(\"fullName\")]</code> or <code>FullNameField = Annotated[str, Alias(\"fullName\")]</code></li> </ul> </li> </ul>"},{"location":"#notable-release-notes","title":"Notable release notes","text":""},{"location":"#450","title":"4.5.0","text":"<ul> <li>Merged <code>databind.core</code> and <code>databind.json</code> packages into <code>databind</code>. The old PyPI packages will remain as proxies   until the next minor version.</li> <li>Dropped support for Python 3.6 and 3.7.</li> </ul> <p>Copyright \u00a9 2022 \u2013 Niklas Rosenstein</p>"},{"location":"basic-usage/","title":"Basic Usage","text":""},{"location":"basic-usage/#implementing-a-custom-converter","title":"Implementing a custom converter","text":"<p>Implementing your own serialization functions is easy. It's often needed, not only when implementing a new serialization format next to the <code>databind.json</code> module, but also to extend an existing serialization format. For example, you may want to add support for serializing your <code>URI</code> custom type to and from a string. You can do this by implementing a custom {@pylink databind.core.converter.Converter}.</p> <pre><code>from dataclasses import dataclass\nfrom urllib.parse import urlparse\nfrom typing import Any\n\nfrom databind.core import Context, Converter\n\n\n@dataclass\nclass URI:\n    scheme: str\n    host: str\n    path: str\n\n    def __str__(self) -&gt; str:\n        return f'{self.scheme}://{self.host}{self.path}'\n\n    class URIConverter(Converter):\n\n        def convert(self, ctx: Context) -&gt; Any:\n            if not isinstance(ctx.datatype, ClassTypeHint) or not issubclass(ctx.datatype.type, URI):\n                raise NotImplementedError\n            if ctx.direction.is_serialize():\n                return str(ctx.value)  # Always serialize into string\n            elif ctx.direction.is_deserialize():\n                if isinstance(ctx.value, str):\n                    parsed = urlparse(ctx.value)\n                    return URI(parsed.scheme, parsed.hostname, parsed.path)\n                # Fall back to other converters, such as default implementation for dataclasses\n                raise NotImplementedError\n            assert False, 'invalid direction'\n</code></pre> <p>To use this new converter, you need to register it to an {@pylink databind.core.mapper.ObjectMapper} instance.</p> <pre><code>from databind.core import ObjectMapper\n\nmapper = ObjectMapper()\nmapper.module.register(URI.URIConverter())\n\nassert mapper.deserialize('https://example.com/foo', URI) == URI('https', 'example.com', '/foo')\nassert mapper.serialize(URI('https', 'example.com', '/foo'), URI) == 'https://example.com/foo'\n</code></pre>"},{"location":"basic-usage/#supporting-settings-in-your-converter","title":"Supporting settings in your converter","text":"<p>What are settings?</p> <p>\"Settings\" are Python objects that are associated with types in the serialization process that can alter the behavior of the converter. Go to Settings to read more about it.</p> <p>Consuming settings in a converter is straight forward. The {@pylink databind.core.context.Context} class provides convenient methods to access settings that are relevant for the current value being processed.</p> <pre><code>#  ...\nfrom databind.core import BooleanSetting\n\n\n@dataclass\nclass URI:\n    # ...\n\n    class SerializeAsString(BooleanSetting):\n        \"\"\"\n        Specifies whether the URI should be serialized to a string.\n        \"\"\"\n\n    class URIConverter(Converter):\n\n        def convert(self, ctx: Context) -&gt; Any:\n            if not isinstance(ctx.datatype, ClassTypeHint) or not issubclass(ctx.datatype.type, URI):\n                raise NotImplementedError\n            if ctx.direction.is_serialize():\n                serialize_as_string = ctx.get_setting(URI.SerializeAsString).enabled\n                if serialize_as_string:\n                    return str(ctx.value)\n                raise NotImplementedError\n            elif ctx.direction.is_deserialize():\n                if isinstance(ctx.value, str):\n                    parsed = urlparse(ctx.value)\n                    return URI(parsed.scheme, parsed.hostname, parsed.path)\n                raise NotImplementedError\n            assert False, 'invalid direction'\n</code></pre> <p>The setting can now be specified when serializing a <code>URI</code> instance as a global setting:</p> <pre><code># ...\n\nfrom databind.core import NoMatchingConverter\nfrom pytest import raises\n\n# When the setting is not enabled, the converter raises a NotImplementedError, having databind search for\n# another applicable converter. Since none exists with an otherwise empty ObjectMapper, this raises a\n# NoMatchingConverter exception.\nwith raises(NoMatchingConverter):\n    mapper.serialize(URI('https', 'example.com', '/foo'), URI)\n\n# Using a global setting, affecting all URI instances being serialized unless a more local setting is specified.\nassert mapper.serialize(\n    URI('htps', 'example.com', '/foo'), URI, settings=[URI.SerializeAsString(True)]) == 'https://example.com/foo'\n</code></pre>"},{"location":"basic-usage/#supporting-typingannotated-type-hints","title":"Supporting <code>typing.Annotated</code> type hints","text":"<p>Converters must explicitly support <code>typing.Annotated</code> type hints. They are often useful to associate settings with a type in a particular case only. There may also be other reasons that a user may want to use an <code>Annotated</code> type hint.</p> <pre><code>class URI:\n    # ...\n\n    class URIConverter(Converter):\n\n        def convert(self, ctx: Context) -&gt; Any:\n            # Check if the type to be converted is supposed to be a URI.\n            datatype = ctx.datatype\n            if isinstance(datatype, AnnotatedTypeHint):\n                datatype = datatype[0]\n            if not isinstance(datatype, ClassTypeHint) or not issubclass(datatype.type, URI):\n                raise NotImplementedError\n\n            # ...\n</code></pre> <p>Now the setting can be specified as an <code>Annotated</code> type hint:</p> <pre><code># Using the Annotated type hint to associate the setting with the type.\nassert mapper.serialize(\n    URI('https', 'example.com', '/foo'), Annoated[URI, URI.SerializeAsString(True)]) == 'https://example.com/foo'\n</code></pre>"},{"location":"basic-usage/#class-decorator-settings","title":"Class-decorator settings","text":"<p>There is also a special class called {@pylink databind.core.settings.ClassDecoratorSetting}, which can be used to create setting types that can decorate classes. The <code>Context.get_settings()</code> method will automatically understand that setting as well.</p>"},{"location":"basic-usage/#simplifying-custom-converts-for-users","title":"Simplifying custom converts for users","text":"<p>Implementing custom converters, especially to convert between strings and custom types, can be a bit tedious. Given that it is quite a common use case, it is usually recommended that a Databind serialization library provide specific settings to simplify the process for users.</p> <p>For example, the <code>databind.json</code> package provides a {@pylink databind.json.settings.JsonConverter} setting that users can use to very easily support the serialization of their custom types to and from strings in a JSON context.</p> <pre><code>from databind.json.settings import JsonConverter\n\n@JsonConverter.using_classmethods(serialize=\"__str__\", deserialize=\"of\")\nclass MyCustomType:\n\n    def __str__(self) -&gt; str:\n        ...\n\n    @staticmethod\n    def of(s: str) -&gt; MyCustomType:\n        ...\n</code></pre>"},{"location":"changelog/","title":"Changelog","text":"<p>@shell cd .. &amp;&amp; slap changelog format --markdown --all</p>"},{"location":"dataclass-ext/","title":"Dataclass extension","text":"<p>The standard library <code>dataclasses</code> module does not allow to define non-default arguments after default arguments. You can use <code>databind.core.dataclasses</code> as a drop-in replacement to get this feature. It behaves exactly like the standard library, only that non-default arguments may follow default arguments. Such arguments can be passed to the constructor as positional or keyword arguments.</p> <p>Note</p> <p>You will loose Mypy type checking support for dataclasses decorated with <code>databind.core.dataclasses.dataclass</code>.</p> <pre><code>from databind.core import dataclasses\n\n@dataclasses.dataclass\nclass A:\n  value1: int = 42\n\n@dataclasses.dataclass\nclass B(A):\n  value2: str\n\nprint(B(0, 'Hello, World!'))\nprint(B(value2='Answer to the universe'))\n</code></pre>"},{"location":"json/","title":"JSON","text":"<p>The <code>databind.json</code> package implements the de-/serialization to or from JSON payloads using the <code>databind.core</code> framework.</p> <p>Check out the Documentation for examples.</p>"},{"location":"json/#built-in-converters","title":"Built-in converters","text":"<p>The following tables shows which types can be deserialized from / serialize to Python types with the native converters provided by the <code>databind.json</code> module:</p> Converter name Types Description <code>AnyConverter</code> <code>typing.Any</code> Accept any value (useful for arbitrary JSON). <code>CollectionConverter</code> <code>typing.Collection[T]</code>, excl. <code>str</code>, <code>bytes</code>, <code>bytearray</code>, <code>memoryview</code> and <code>typing.Mapping[K, V]</code> Converts between native Python collections and JSON arrays. <code>DatetimeConverter</code> <code>datetime.date</code>, <code>datetime.datetime</code>, <code>datetime.time</code> Converts between strings and date/time formats, using ISO 8601 time format by default (can be changed with the <code>databind.core.settings.DateFormat</code> setting). <code>DecimalConverter</code> <code>decimal.Decimal</code> Converts between strings (and ints/floats if strict mode is off, strict mode is on by default) and decimals. The precision can be controlled with the <code>databind.core.settings.Precision</code> setting. <code>EnumConverter</code> <code>enum.Enum</code>, <code>enum.IntEnum</code> Convert between strings and Python enumerations. The serialized form of <code>IntEnum</code> is the integer value, whereas the serialized form of <code>Enum</code> is a string (name of the enumeration value). <code>MappingConverter</code> <code>typing.Mapping[K, V]</code> Converts between Python dicts and JSON objects. (While in theory <code>K</code> can be any type, for JSON <code>K</code> always needs to be <code>str</code>). <code>OptionalConverter</code> <code>typing.Optional[T]</code> Handles optional fields in a schema. <code>PlainDatatypeConverter</code> <code>bytes</code>, <code>str</code>, <code>int</code>, <code>float</code>, <code>bool</code> Converts between plain datatypes. In non-strict mode (off by default), numeric types will also accept strings as input for the deserialization. <code>SchemaConverter</code> <code>dataclasses.dataclass</code>, <code>typing.TypedDict</code> Converts between Python dataclasses or typed dictionary and JSON objects. <code>UnionConverter</code> <code>typing.Union[...]</code> Handles union types. Unions in JSON can be expressed in a multitide of ways, e.g. using a discriminator key and flat, keyed or nested structure or \"best match\". Check out the examples section of the documentation for more information. <code>LiteralConverter</code> <code>typing.Literal[...]</code> Accepts or rejects a value based on whether it matches one of the values in the literal type hint. <p>The following converters are provided for convenience:</p> Converter name Types Description <code>StringifyConverter</code> n/a A helper that allows to easily create de/serializers from a \"to string\" and \"from string\" function. <p>The following additional types are natively supported by <code>databind.json</code> using <code>StringifyConverter</code>:</p> Types Description <code>uuid.UUID</code> Convert between strings and UUIDs. <code>pathlib.Path</code> Convert between strings and paths. <code>pathlib.PurePath</code> Convert between strings and paths. <code>nr.date.duration</code> Deserialize from ISO 8601 duration strings or the object form, serialize to ISO 8601 strings. <p>Copyright \u00a9 2020 \u2013 Niklas Rosenstein</p>"},{"location":"pitfalls/","title":"Pitfalls","text":""},{"location":"pitfalls/#missing-type-parameters","title":"Missing type parameters","text":"<p>Databind will not simply assume <code>Any</code> for a type hint when it is not set. Instead, it will raise an error like to following when an unbound type parameter is encountered:</p> <pre><code>databind.core.converter.NoMatchingConverter: no deserializer for `TypeHint(~T_Page)` and payload of type `dict`\n</code></pre> <p>Note: The handling of missing type parameter depends on the serde implementation (e.g. <code>databind.json</code>), but it is a convention that all implementations should follow by default.</p> <p>Examples</p> <p>(1)</p> <pre><code>from databind.json import load\n\nload([1, \"foo\", {\"name\": \"Doe\"}], list)  # could not find item type in TypeHint(list)\n</code></pre> <p>(2)</p> <pre><code>from dataclasses import dataclass\nfrom databind.json import load\nfrom typing import Generic, TypeVar\n\nT = TypeVar(\"T\", bound=\"MyClass\")\n\n@dataclass\nclass MyClass(Generic[T]):\n    children: list[T]\n\nload({\"children\": [{\"children\": []}]}, MyClass)  # no deserializer for `TypeHint(~T)` and payload of type `dict`\n</code></pre> <p>The example (2) can only be fixed by creating a dedicated subclass:</p> <pre><code>@dataclass\nclass MySpecificClass(MyClass[\"MySpecificClass\"]):\n    pass\n\nload({\"children\": [{\"children\": []}]}, MySpecificClass)\n</code></pre>"},{"location":"settings/","title":"Settings","text":"<p>Settings in Databind are Python objects that convey additional information to the serialization process. A setting must be expicitly supported by a {@pylink databind.core.converter.Converter} in order to take effect. As such, all settings provided by <code>databind.core</code> merely provide a standard set of settings that should but may not all be supported by serialization lirbary implementations.</p> <p>Settings must be subclasses from {@pylink databind.core.settings.Setting}, {@pylink databind.core.settings.BooleanSetting} or {@pylink databind.core.settings.ClassDecoratedSetting}.</p>"},{"location":"settings/#specifying-settings","title":"Specifying settings","text":"<p>You can specify settings at various places in your code to make them apply at various stages during the serialization. The following list shows the order of precedence, from highest to lowest:</p> <ol> <li>Type-hint local settings specified in the metadata of <code>typing.Annotated</code> hints.</li> <li>Settings that were used to annotate a type.</li> <li>Global settings that are passed to {@pylink databind.core.mapper.ObjectMapper.convert}, or the respective   <code>serialize</code>/<code>deserialize</code> methods.</li> </ol>"},{"location":"settings/#settings-priority","title":"Settings priority","text":"<p>The above precedence only takes effect within the same priority group. The priority of all setting defaults to <code>NORMAL</code> unless specified otherwise. The following priority groups exist:</p> <ul> <li><code>LOW</code>: Settings with this priority group are resolved after <code>NORMAL</code> settings.</li> <li><code>NORMAL</code>: The default priority group.</li> <li><code>HIGH</code>: Settings with this priority group are resolved before <code>NORMAL</code> settings.</li> <li><code>ULTIMATE</code>: Settings with this priority group are resolved before <code>HIGH</code> settings.</li> </ul> <p>Converters are usually only interested in the first instance of any setting type.</p>"},{"location":"settings/#notes-about-implementing-custom-settings","title":"Notes about implementing custom settings","text":"<p>To support Python 3.6, <code>typing_extensions.Annotated</code> metadata must be hashable. As such, settings that you want users to be able to pass into annotated type hints in Python 3.6 must support hashing (identity hashing is often sufficient).</p>"},{"location":"api/databind.core/","title":"databind.core","text":""},{"location":"api/databind.core/#databind.core","title":"databind.core","text":""},{"location":"api/databind.core/#databind.core.Alias","title":"Alias","text":"<p>             Bases: <code>Setting</code></p> <p>The #Alias setting is used to attach one or more alternative names to a dataclass field that should be used instead of the field's name in the code.</p> <p>Example:</p> <pre><code>import typing\nfrom dataclasses import dataclass\nfrom databind.core.settings import Alias\n\n@dataclass\nclass MyClass:\n  my_field: typing.Annotated[int, Alias('foobar', 'spam')]\n</code></pre> <p>When deserializing a payload, converters should now use <code>foobar</code> if it exists, or fall back to <code>spam</code> when looking up the value for the field in the payload as opposed to <code>my_field</code>. When serializing, converters should use <code>foobar</code> as the name in the generated payload (always the first alias).</p> Source code in <code>databind/core/settings.py</code> <pre><code>class Alias(Setting):\n    \"\"\"The #Alias setting is used to attach one or more alternative names to a dataclass field that should be used\n    instead of the field's name in the code.\n\n    Example:\n\n    ```py\n    import typing\n    from dataclasses import dataclass\n    from databind.core.settings import Alias\n\n    @dataclass\n    class MyClass:\n      my_field: typing.Annotated[int, Alias('foobar', 'spam')]\n    ```\n\n    When deserializing a payload, converters should now use `foobar` if it exists, or fall back to `spam` when looking\n    up the value for the field in the payload as opposed to `my_field`. When serializing, converters should use `foobar`\n    as the name in the generated payload (always the first alias).\n    \"\"\"\n\n    #: A tuple of the aliases provided to the constructor.\n    aliases: t.Tuple[str, ...]\n    priority: Priority = Priority.NORMAL\n\n    def __init__(self, alias: str, *additional_aliases: str, priority: Priority = Priority.NORMAL) -&gt; None:\n        self.aliases = (alias,) + additional_aliases\n        self.priority = priority\n\n    def __repr__(self) -&gt; str:\n        return f'Alias({\", \".join(map(repr, self.aliases))}, priority={self.priority!r})'\n</code></pre>"},{"location":"api/databind.core/#databind.core.BooleanSetting","title":"BooleanSetting  <code>dataclass</code>","text":"<p>             Bases: <code>Setting</code></p> <p>Base class for boolean settings.</p> Source code in <code>databind/core/settings.py</code> <pre><code>@dataclasses.dataclass(frozen=True)\nclass BooleanSetting(Setting):\n    \"\"\"Base class for boolean settings.\"\"\"\n\n    enabled: bool = True\n    priority: Priority = Priority.NORMAL\n\n    def __post_init__(self) -&gt; None:\n        if type(self) is BooleanSetting:\n            raise TypeError(\"BooleanSetting cannot be directly instantiated\")\n</code></pre>"},{"location":"api/databind.core/#databind.core.ClassDecoratorSetting","title":"ClassDecoratorSetting","text":"<p>             Bases: <code>Setting</code></p> Source code in <code>databind/core/settings.py</code> <pre><code>class ClassDecoratorSetting(Setting):\n    bound_to: t.Optional[type] = None\n\n    def __init__(self) -&gt; None:\n        if type(self) is ClassDecoratorSetting:\n            raise TypeError(\"ClassDecoratorSetting cannot be directly instantiated\")\n        super().__init__()\n\n    def __call__(self, type_: t.Type[T]) -&gt; t.Type[T]:\n        \"\"\"Decorate the class *type_* with this setting, adding the setting to its `__databind_settings__` list\n        (which is created if it does not exist) and sets #bound_to. The same setting instance cannot decorate multiple\n        types.\"\"\"\n\n        assert isinstance(type_, type), type_\n        if self.bound_to is not None:\n            raise RuntimeError(\"cannot decorate multiple types with the same setting instance\")\n\n        self.bound_to = type_\n        settings = getattr(type_, \"__databind_settings__\", None)\n        if settings is None:\n            settings = []\n            setattr(type_, \"__databind_settings__\", settings)\n        settings.append(self)\n\n        return type_\n</code></pre>"},{"location":"api/databind.core/#databind.core.ClassDecoratorSetting.__call__","title":"__call__","text":"<pre><code>__call__(type_: Type[T]) -&gt; Type[T]\n</code></pre> <p>Decorate the class type_ with this setting, adding the setting to its <code>__databind_settings__</code> list (which is created if it does not exist) and sets #bound_to. The same setting instance cannot decorate multiple types.</p> Source code in <code>databind/core/settings.py</code> <pre><code>def __call__(self, type_: t.Type[T]) -&gt; t.Type[T]:\n    \"\"\"Decorate the class *type_* with this setting, adding the setting to its `__databind_settings__` list\n    (which is created if it does not exist) and sets #bound_to. The same setting instance cannot decorate multiple\n    types.\"\"\"\n\n    assert isinstance(type_, type), type_\n    if self.bound_to is not None:\n        raise RuntimeError(\"cannot decorate multiple types with the same setting instance\")\n\n    self.bound_to = type_\n    settings = getattr(type_, \"__databind_settings__\", None)\n    if settings is None:\n        settings = []\n        setattr(type_, \"__databind_settings__\", settings)\n    settings.append(self)\n\n    return type_\n</code></pre>"},{"location":"api/databind.core/#databind.core.Context","title":"Context  <code>dataclass</code>","text":"<p>The context is constructed by the #ObjectMapper and passed to an applicable #Converter to convert #value according to the #datatype.</p> Source code in <code>databind/core/context.py</code> <pre><code>@dataclasses.dataclass\nclass Context:\n    \"\"\"The context is constructed by the #ObjectMapper and passed to an applicable #Converter to convert #value\n    according to the #datatype.\"\"\"\n\n    #: The parent context.\n    parent: t.Optional[\"Context\"] = dataclasses.field(repr=False)\n\n    #: The direction (i.e. deserialization or serialization).\n    direction: Direction\n\n    #: The value to convert.\n    value: t.Any = dataclasses.field(repr=False)\n\n    #: The expected datatype of the value to inform the converter of what to convert the #value from or to.\n    datatype: TypeHint\n\n    #: A list of #Setting#s that are to be taken into account by the converter which can potentialy impact\n    #: the conversion process.\n    settings: \"SettingsProvider\" = dataclasses.field(repr=False)\n\n    #: The key or index under which #value is present in the source material relative to the #parent context.\n    #: This is `None` only for the root value in the same source. The value must be #Context.ROOT if the context\n    #: has no parent.\n    key: t.Union[int, str, Root, None, t.Any]\n\n    #: The location of the #value in the source material.\n    location: Location\n\n    #: A function to dispatch the further conversion of a #Context.\n    convert_func: t.Callable[[\"Context\"], t.Any] = dataclasses.field(repr=False)\n\n    ROOT: t.ClassVar = Root.Value\n\n    def __post_init__(self) -&gt; None:\n        assert isinstance(self.datatype, TypeHint), self.datatype\n        assert self.location is not None\n        assert self.parent is not None or self.key == Context.ROOT\n\n    def get_setting(self, setting_type: t.Type[\"T_Setting\"]) -&gt; \"T_Setting | None\":\n        \"\"\"Retrieve a setting by type that for the current context.\"\"\"\n\n        return self.settings.get_setting(self, setting_type)\n\n    def spawn(\n        self,\n        value: t.Any,\n        datatype: t.Union[TypeHint, t.Any],\n        key: t.Union[int, str, None],\n        location: t.Optional[Location] = None,\n    ) -&gt; \"Context\":\n        \"\"\"Spawn a sub context with a new value, datatype, key and optionally a new location. If the location is\n        not overwritten, the parent filename is inherited, but not line number and column.\n\n        Arguments:\n          value: The value to convert.\n          datatype: The datatype of *value*. If this is not already a #TypeHint, it will be converted to one\n            using #TypeHint().\n          key: The key or index at which the *value* can be found relative to the parent.\n          location: The location of the new value. If not specified, the parent filename is inherited but not the\n            line number and column.\n        Returns:\n          A new #Context object that has *self* as its #parent.\n        \"\"\"\n\n        if not isinstance(datatype, TypeHint):\n            datatype = TypeHint(datatype)\n\n        if location is None:\n            location = Location(self.location.filename, None, None)\n\n        return Context(self, self.direction, value, datatype, self.settings, key, location, self.convert_func)\n\n    def convert(self) -&gt; t.Any:\n        \"\"\"Invoke the #convert_func with *self*.\"\"\"\n\n        return self.convert_func(self)\n\n    def iter_hierarchy_up(self) -&gt; t.Iterable[\"Context\"]:\n        current: t.Optional[Context] = self\n        while current:\n            yield current\n            current = current.parent\n</code></pre>"},{"location":"api/databind.core/#databind.core.Context.convert","title":"convert","text":"<pre><code>convert() -&gt; Any\n</code></pre> <p>Invoke the #convert_func with self.</p> Source code in <code>databind/core/context.py</code> <pre><code>def convert(self) -&gt; t.Any:\n    \"\"\"Invoke the #convert_func with *self*.\"\"\"\n\n    return self.convert_func(self)\n</code></pre>"},{"location":"api/databind.core/#databind.core.Context.get_setting","title":"get_setting","text":"<pre><code>get_setting(setting_type: Type[T_Setting]) -&gt; T_Setting | None\n</code></pre> <p>Retrieve a setting by type that for the current context.</p> Source code in <code>databind/core/context.py</code> <pre><code>def get_setting(self, setting_type: t.Type[\"T_Setting\"]) -&gt; \"T_Setting | None\":\n    \"\"\"Retrieve a setting by type that for the current context.\"\"\"\n\n    return self.settings.get_setting(self, setting_type)\n</code></pre>"},{"location":"api/databind.core/#databind.core.Context.spawn","title":"spawn","text":"<pre><code>spawn(value: Any, datatype: Union[TypeHint, Any], key: Union[int, str, None], location: Optional[Location] = None) -&gt; Context\n</code></pre> <p>Spawn a sub context with a new value, datatype, key and optionally a new location. If the location is not overwritten, the parent filename is inherited, but not line number and column.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>Any</code> <p>The value to convert.</p> required <code>datatype</code> <code>Union[TypeHint, Any]</code> <p>The datatype of value. If this is not already a #TypeHint, it will be converted to one using #TypeHint().</p> required <code>key</code> <code>Union[int, str, None]</code> <p>The key or index at which the value can be found relative to the parent.</p> required <code>location</code> <code>Optional[Location]</code> <p>The location of the new value. If not specified, the parent filename is inherited but not the line number and column.</p> <code>None</code> <p>Returns:   A new #Context object that has self as its #parent.</p> Source code in <code>databind/core/context.py</code> <pre><code>def spawn(\n    self,\n    value: t.Any,\n    datatype: t.Union[TypeHint, t.Any],\n    key: t.Union[int, str, None],\n    location: t.Optional[Location] = None,\n) -&gt; \"Context\":\n    \"\"\"Spawn a sub context with a new value, datatype, key and optionally a new location. If the location is\n    not overwritten, the parent filename is inherited, but not line number and column.\n\n    Arguments:\n      value: The value to convert.\n      datatype: The datatype of *value*. If this is not already a #TypeHint, it will be converted to one\n        using #TypeHint().\n      key: The key or index at which the *value* can be found relative to the parent.\n      location: The location of the new value. If not specified, the parent filename is inherited but not the\n        line number and column.\n    Returns:\n      A new #Context object that has *self* as its #parent.\n    \"\"\"\n\n    if not isinstance(datatype, TypeHint):\n        datatype = TypeHint(datatype)\n\n    if location is None:\n        location = Location(self.location.filename, None, None)\n\n    return Context(self, self.direction, value, datatype, self.settings, key, location, self.convert_func)\n</code></pre>"},{"location":"api/databind.core/#databind.core.ConversionError","title":"ConversionError","text":"<p>             Bases: <code>Exception</code></p> <p>For any errors that occur during conversion.</p> Source code in <code>databind/core/converter.py</code> <pre><code>class ConversionError(Exception):\n    \"\"\"For any errors that occur during conversion.\"\"\"\n\n    def __init__(\n        self,\n        origin: Converter,\n        context: \"Context\",\n        message: str,\n        errors: \"t.Sequence[t.Tuple[Converter, Exception]] | None\" = None,\n    ) -&gt; None:\n        self.origin = origin\n        self.context = context\n        self.message = message\n        self.errors = errors or []\n\n    @exception_safe_str\n    def __str__(self) -&gt; str:\n        import textwrap\n\n        from databind.core.context import format_context_trace\n\n        message = f'{self.message}\\n\\nTrace:\\n{textwrap.indent(format_context_trace(self.context), \"  \")}'\n        if self.errors:\n            message += \"\\n\\nThe following errors have been reported by converters:\"\n            for converter, exc in self.errors:\n                if str(exc):\n                    message += f\"\\n\\n  {converter}: {indent(str(exc), '    ').lstrip()}\"\n        return message\n\n    @staticmethod\n    def expected(\n        origin: Converter,\n        ctx: \"Context\",\n        types: t.Union[type, t.Sequence[type]],\n        got: t.Optional[type] = None,\n    ) -&gt; \"ConversionError\":\n        if not isinstance(types, t.Sequence):\n            types = (types,)\n        expected = \"|\".join(type_repr(t) for t in types)\n        got = type(ctx.value) if got is None else got\n        return ConversionError(origin, ctx, f\"expected {expected}, got {type_repr(got)} instead\")\n</code></pre>"},{"location":"api/databind.core/#databind.core.Converter","title":"Converter","text":"<p>             Bases: <code>ABC</code></p> <p>Interface for converting a value from one representation to another.</p> Source code in <code>databind/core/converter.py</code> <pre><code>class Converter(abc.ABC):\n    \"\"\"Interface for converting a value from one representation to another.\"\"\"\n\n    def __repr__(self) -&gt; str:\n        return f\"{type_repr(type(self))}()\"\n\n    def convert(self, ctx: \"Context\") -&gt; t.Any:\n        \"\"\"Convert the value in *ctx* to another value.\n\n        The default implementation will dispatch to #serialize() and #deserialize() depending on the direction\n        given by the context. Because these methods raise #NotImplementedError, an instance of #Converter without\n        custom logic will effectively be a no-op.\n\n        Argument:\n          ctx: The conversion context that contains the direction, value, datatype, settings, location and allows\n            you to recursively continue the conversion process for sub values.\n\n        Raises:\n          NotImplementedError: If the converter does not support the conversion for the given context.\n          NoMatchingConverter: If the converter is delegating to other converters, to point out that none\n            of its delegates can convert the value.\n\n        Returns:\n          The new value.\n        \"\"\"\n\n        if ctx.direction.is_serialize():\n            return self.serialize(ctx)\n        elif ctx.direction.is_deserialize():\n            return self.deserialize(ctx)\n        else:\n            raise RuntimeError(f\"unexpected direction: {ctx.direction!r}\")\n\n    def serialize(self, ctx: \"Context\") -&gt; t.Any:\n        raise NotImplementedError\n\n    def deserialize(self, ctx: \"Context\") -&gt; t.Any:\n        raise NotImplementedError\n</code></pre>"},{"location":"api/databind.core/#databind.core.Converter.convert","title":"convert","text":"<pre><code>convert(ctx: Context) -&gt; Any\n</code></pre> <p>Convert the value in ctx to another value.</p> <p>The default implementation will dispatch to #serialize() and #deserialize() depending on the direction given by the context. Because these methods raise #NotImplementedError, an instance of #Converter without custom logic will effectively be a no-op.</p> Argument <p>ctx: The conversion context that contains the direction, value, datatype, settings, location and allows   you to recursively continue the conversion process for sub values.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If the converter does not support the conversion for the given context.</p> <code>NoMatchingConverter</code> <p>If the converter is delegating to other converters, to point out that none of its delegates can convert the value.</p> <p>Returns:</p> Type Description <code>Any</code> <p>The new value.</p> Source code in <code>databind/core/converter.py</code> <pre><code>def convert(self, ctx: \"Context\") -&gt; t.Any:\n    \"\"\"Convert the value in *ctx* to another value.\n\n    The default implementation will dispatch to #serialize() and #deserialize() depending on the direction\n    given by the context. Because these methods raise #NotImplementedError, an instance of #Converter without\n    custom logic will effectively be a no-op.\n\n    Argument:\n      ctx: The conversion context that contains the direction, value, datatype, settings, location and allows\n        you to recursively continue the conversion process for sub values.\n\n    Raises:\n      NotImplementedError: If the converter does not support the conversion for the given context.\n      NoMatchingConverter: If the converter is delegating to other converters, to point out that none\n        of its delegates can convert the value.\n\n    Returns:\n      The new value.\n    \"\"\"\n\n    if ctx.direction.is_serialize():\n        return self.serialize(ctx)\n    elif ctx.direction.is_deserialize():\n        return self.deserialize(ctx)\n    else:\n        raise RuntimeError(f\"unexpected direction: {ctx.direction!r}\")\n</code></pre>"},{"location":"api/databind.core/#databind.core.DateFormat","title":"DateFormat  <code>dataclass</code>","text":"<p>             Bases: <code>Setting</code></p> <p>The #DateFormat setting is used to describe the date format to use for #datetime.datetime, #datetime.date and #datetime.time values when formatting them as a string, i.e. usually when the date/time is serialized, and when parsing them.</p> <p>The #nr.date module provides types to describe the format of a date, time and datetime (see #date_format,</p>"},{"location":"api/databind.core/#databind.core.DateFormat--time_format-and-datetime_format-as-well-as-an-entire-suite-of-formats-for-all-types-of-datetime-values","title":"time_format and #datetime_format), as well as an entire suite of formats for all types of date/time values.","text":"<p>Parameters:</p> Name Type Description Default <code>formats</code> <code>T_Input</code> <p>One or more datetime formats to use when parsing. The first of the formats is used for formatting. Each element must be one of the following:</p> <ul> <li>A formatter (like #date_format, #time_format or #datetime_format),</li> <li>a #format_set,</li> <li>a string that is a date/time format, or</li> <li>a string starting with a period (<code>.</code>) that names a builtin format set (like <code>.ISO_8601</code>)</li> </ul> <p>Attempting to use #parse() or #format() for a date/time value type for which the #DateFormat does not provide an applicable format results in a #ValueError.</p> <code>()</code> Source code in <code>databind/core/settings.py</code> <pre><code>@dataclasses.dataclass(init=False, unsafe_hash=True)\nclass DateFormat(Setting):\n    \"\"\"The #DateFormat setting is used to describe the date format to use for #datetime.datetime, #datetime.date\n    and #datetime.time values when formatting them as a string, i.e. usually when the date/time is serialized, and\n    when parsing them.\n\n    The #nr.date module provides types to describe the format of a date, time and datetime (see #date_format,\n    #time_format and #datetime_format), as well as an entire suite of formats for all types of date/time values.\n\n    Arguments:\n      formats: One or more datetime formats to use when parsing. The first of the formats is used for formatting.\n        Each element must be one of the following:\n\n        * A formatter (like #date_format, #time_format or #datetime_format),\n        * a #format_set,\n        * a string that is a date/time format, or\n        * a string starting with a period (`.`) that names a builtin format set (like `.ISO_8601`)\n\n        Attempting to use #parse() or #format() for a date/time value type for which the #DateFormat does not\n        provide an applicable format results in a #ValueError.\n    \"\"\"\n\n    Dtype = t.Union[datetime.date, datetime.time, datetime.datetime]\n    Formatter = t.Union[\"date_format\", \"time_format\", \"datetime_format\", \"format_set\"]\n    T_Input = t.Union[str, Formatter]\n    T_Dtype = t.TypeVar(\"T_Dtype\", bound=Dtype)\n\n    formats: t.Sequence[T_Input]\n\n    def __init__(self, *formats: T_Input) -&gt; None:\n        if not formats:\n            raise ValueError(\"need at least one date format\")\n        self.formats = formats\n\n    @staticmethod\n    def __get_builtin_format(fmt: str) -&gt; Formatter:\n        if fmt == \".ISO_8601\":\n            from nr.date.format_sets import ISO_8601\n\n            return ISO_8601\n        if fmt == \".JAVA_OFFSET_DATETIME\":\n            from nr.date.format_sets import JAVA_OFFSET_DATETIME\n\n            return JAVA_OFFSET_DATETIME\n        raise ValueError(f\"{fmt!r} is not a built-in date/time format set\")\n\n    def __iter_formats(self, type_: t.Type[Formatter]) -&gt; t.Iterable[Formatter]:\n        for fmt in self.formats:\n            if isinstance(fmt, str):\n                if fmt.startswith(\".\"):\n                    yield self.__get_builtin_format(fmt)\n                else:\n                    yield type_.compile(fmt)  # type: ignore\n            elif type(fmt) is type_:\n                yield fmt\n            elif isinstance(fmt, format_set):\n                yield from getattr(fmt, type_.__name__ + \"s\")\n            # else:\n            #  raise RuntimeError(f'bad date format type: {type(fmt).__name__}')\n\n    def parse(self, type_: t.Type[T_Dtype], value: str) -&gt; T_Dtype:\n        \"\"\"Parse a date/time value from a string.\n\n        Arguments:\n          type_: The type to parse the value into, i.e. #datetime.date, #datetime.time or #datetime.datetime.\n          value: The string to parse.\n        Raises:\n          ValueError: If no date format is sufficient to parse *value* into the given *type_*.\n        Returns:\n          The parsed date/time value.\n        \"\"\"\n\n        from nr.date import date_format, datetime_format, time_format\n\n        format_t: t.Type[DateFormat.Formatter]\n        format_t, method_name = {  # type: ignore\n            datetime.date: (date_format, \"parse_date\"),\n            datetime.time: (time_format, \"parse_time\"),\n            datetime.datetime: (datetime_format, \"parse_datetime\"),\n        }[type_]\n        for fmt in self.__iter_formats(format_t):\n            try:\n                return t.cast(DateFormat.T_Dtype, getattr(fmt, method_name)(value))\n            except ValueError:\n                pass\n        raise self._formulate_parse_error(list(self.__iter_formats(format_t)), value)\n\n    def format(self, dt: T_Dtype) -&gt; str:\n        \"\"\"Format a date/time value to a string.\n\n        Arguments:\n          dt: The date/time value to format (i.e. an instance of #datetime.date, #datetime.time or\n            #datetime.datetime).\n        Raises:\n          ValueError: If no date format to format the type of *value* is available.\n        Returns:\n          The formatted date/time value.\n        \"\"\"\n\n        from nr.date import date_format, datetime_format, time_format\n\n        format_t: t.Type[DateFormat.Formatter]\n        format_t, method_name = {  # type: ignore\n            datetime.date: (date_format, \"format_date\"),\n            datetime.time: (time_format, \"format_time\"),\n            datetime.datetime: (datetime_format, \"format_datetime\"),\n        }[type(dt)]\n        for fmt in self.__iter_formats(format_t):\n            try:\n                return t.cast(str, getattr(fmt, method_name)(dt))\n            except ValueError:\n                pass\n        raise self._formulate_parse_error(list(self.__iter_formats(format_t)), dt)\n\n    @staticmethod\n    def _formulate_parse_error(formats: t.Sequence[Formatter], s: t.Any) -&gt; ValueError:\n        return ValueError(\n            f'\"{s}\" does not match date formats ({len(formats)}):'\n            + \"\".join(f\"\\n  | {str(x) if isinstance(x, format_set) else x.format_str}\" for x in formats)\n        )\n</code></pre>"},{"location":"api/databind.core/#databind.core.DateFormat.format","title":"format","text":"<pre><code>format(dt: T_Dtype) -&gt; str\n</code></pre> <p>Format a date/time value to a string.</p> <p>Parameters:</p> Name Type Description Default <code>dt</code> <code>T_Dtype</code> <p>The date/time value to format (i.e. an instance of #datetime.date, #datetime.time or</p> required <p>Raises:   ValueError: If no date format to format the type of value is available. Returns:   The formatted date/time value.</p> Source code in <code>databind/core/settings.py</code> <pre><code>def format(self, dt: T_Dtype) -&gt; str:\n    \"\"\"Format a date/time value to a string.\n\n    Arguments:\n      dt: The date/time value to format (i.e. an instance of #datetime.date, #datetime.time or\n        #datetime.datetime).\n    Raises:\n      ValueError: If no date format to format the type of *value* is available.\n    Returns:\n      The formatted date/time value.\n    \"\"\"\n\n    from nr.date import date_format, datetime_format, time_format\n\n    format_t: t.Type[DateFormat.Formatter]\n    format_t, method_name = {  # type: ignore\n        datetime.date: (date_format, \"format_date\"),\n        datetime.time: (time_format, \"format_time\"),\n        datetime.datetime: (datetime_format, \"format_datetime\"),\n    }[type(dt)]\n    for fmt in self.__iter_formats(format_t):\n        try:\n            return t.cast(str, getattr(fmt, method_name)(dt))\n        except ValueError:\n            pass\n    raise self._formulate_parse_error(list(self.__iter_formats(format_t)), dt)\n</code></pre>"},{"location":"api/databind.core/#databind.core.DateFormat.format--datetimedatetime","title":"datetime.datetime).","text":""},{"location":"api/databind.core/#databind.core.DateFormat.parse","title":"parse","text":"<pre><code>parse(type_: Type[T_Dtype], value: str) -&gt; T_Dtype\n</code></pre> <p>Parse a date/time value from a string.</p> <p>Parameters:</p> Name Type Description Default <code>type_</code> <code>Type[T_Dtype]</code> <p>The type to parse the value into, i.e. #datetime.date, #datetime.time or #datetime.datetime.</p> required <code>value</code> <code>str</code> <p>The string to parse.</p> required <p>Raises:   ValueError: If no date format is sufficient to parse value into the given type_. Returns:   The parsed date/time value.</p> Source code in <code>databind/core/settings.py</code> <pre><code>def parse(self, type_: t.Type[T_Dtype], value: str) -&gt; T_Dtype:\n    \"\"\"Parse a date/time value from a string.\n\n    Arguments:\n      type_: The type to parse the value into, i.e. #datetime.date, #datetime.time or #datetime.datetime.\n      value: The string to parse.\n    Raises:\n      ValueError: If no date format is sufficient to parse *value* into the given *type_*.\n    Returns:\n      The parsed date/time value.\n    \"\"\"\n\n    from nr.date import date_format, datetime_format, time_format\n\n    format_t: t.Type[DateFormat.Formatter]\n    format_t, method_name = {  # type: ignore\n        datetime.date: (date_format, \"parse_date\"),\n        datetime.time: (time_format, \"parse_time\"),\n        datetime.datetime: (datetime_format, \"parse_datetime\"),\n    }[type_]\n    for fmt in self.__iter_formats(format_t):\n        try:\n            return t.cast(DateFormat.T_Dtype, getattr(fmt, method_name)(value))\n        except ValueError:\n            pass\n    raise self._formulate_parse_error(list(self.__iter_formats(format_t)), value)\n</code></pre>"},{"location":"api/databind.core/#databind.core.DelegateToClassmethodConverter","title":"DelegateToClassmethodConverter","text":"<p>             Bases: <code>Converter</code></p> <p>This converter delegaes to the methods defined by name to perform serialization and deserialization of a type. This converter is usually used in conjunction with settings that override the converteer to be used in a specifc scenario (e.g. such as de/serializing JSON with the #databind.json.settings.JsonConverter setting).</p> Source code in <code>databind/core/converter.py</code> <pre><code>class DelegateToClassmethodConverter(Converter):\n    \"\"\"\n    This converter delegaes to the methods defined by name to perform serialization and deserialization of a type. This\n    converter is usually used in conjunction with settings that override the converteer to be used in a specifc\n    scenario (e.g. such as de/serializing JSON with the #databind.json.settings.JsonConverter setting).\n    \"\"\"\n\n    def __init__(\n        self,\n        serialized_type: t.Union[t.Type[t.Any], t.Tuple[t.Type[t.Any], ...], None] = None,\n        *,\n        serialize: \"str | None\" = None,\n        deserialize: \"str | None\" = None,\n    ) -&gt; None:\n        self._serialized_type = serialized_type\n        self._serialize = serialize\n        self._deserialize = deserialize\n\n    def serialize(self, ctx: \"Context\") -&gt; t.Any:\n        if self._serialize is None or not isinstance(ctx.datatype, ClassTypeHint):\n            raise NotImplementedError\n        if not isinstance(ctx.value, ctx.datatype.type):\n            raise ConversionError.expected(self, ctx, ctx.datatype.type)\n        method: t.Callable[[t.Any], t.Any] = getattr(ctx.datatype.type, self._serialize)\n        return method(ctx.value)\n\n    def deserialize(self, ctx: \"Context\") -&gt; t.Any:\n        if self._deserialize is None or not isinstance(ctx.datatype, ClassTypeHint):\n            raise NotImplementedError\n        if self._serialized_type is not None and not isinstance(ctx.value, self._serialized_type):\n            raise ConversionError.expected(self, ctx, self._serialized_type)\n        method: t.Callable[[t.Any], t.Any] = getattr(ctx.datatype.type, self._deserialize)\n        return method(ctx.value)\n</code></pre>"},{"location":"api/databind.core/#databind.core.DeserializeAs","title":"DeserializeAs  <code>dataclass</code>","text":"<p>             Bases: <code>Setting</code></p> <p>Indicates that a field should be deserialized as the given type instead of the type of the field. This is typically used when a field should be typed as an abstract class or interface, but during deserialization of the field, a concrete type should be used instead.</p> <p>Example:</p> <pre><code>import typing\nfrom dataclasses import dataclass\nfrom databind.core.settings import DeserializeAs\n\n@dataclass\nclass A:\n    pass\n\n@dataclass\nclass B(A):\n    pass\n\n@dataclass\nclass MyClass:\n  my_field: typing.Annotated[A, DeserializeAs(B)]\n</code></pre> <p>Here, although <code>MyClass.my_field</code> is annotated as <code>A</code>, when a payload is deserialized into an instance of <code>MyClass</code>, the value for <code>my_field</code> will be deserialized as an instance of <code>B</code> instead of <code>A</code>.</p> Source code in <code>databind/core/settings.py</code> <pre><code>@dataclasses.dataclass(frozen=True)\nclass DeserializeAs(Setting):\n    \"\"\"Indicates that a field should be deserialized as the given type instead of the type of the field. This is\n    typically used when a field should be typed as an abstract class or interface, but during deserialization of the\n    field, a concrete type should be used instead.\n\n    Example:\n\n    ```py\n    import typing\n    from dataclasses import dataclass\n    from databind.core.settings import DeserializeAs\n\n    @dataclass\n    class A:\n        pass\n\n    @dataclass\n    class B(A):\n        pass\n\n    @dataclass\n    class MyClass:\n      my_field: typing.Annotated[A, DeserializeAs(B)]\n    ```\n\n    Here, although `MyClass.my_field` is annotated as `A`, when a payload is deserialized into an instance of\n    `MyClass`, the value for `my_field` will be deserialized as an instance of `B` instead of `A`.\n    \"\"\"\n\n    type: t.Type[t.Any]\n    priority: Priority = Priority.NORMAL\n</code></pre>"},{"location":"api/databind.core/#databind.core.ExtraKeys","title":"ExtraKeys","text":"<p>             Bases: <code>ClassDecoratorSetting</code></p> <p>If discovered while deserializing a #databind.core.schema.Schema, it's callback is used to inform when extras keys are encountered. If the setting is not available, or if the arg is set to <code>False</code> (the default), it will cause an error.</p> <p>The setting may also be supplied at an individual schema level.</p> <p>Can be used as a decorator for a class to indicate that extra keys on the schema informed by the class are allowed, as a global setting or as an annotation on a schema field.</p> <p>Note</p> <p>Only the first, highest priority annotation is used; thus if you pass a callback for arg it may not be called if the #ExtraKeys setting you pass it to is overruled by another.</p> Source code in <code>databind/core/settings.py</code> <pre><code>class ExtraKeys(ClassDecoratorSetting):\n    \"\"\"If discovered while deserializing a #databind.core.schema.Schema, it's callback is used to inform when extras\n    keys are encountered. If the setting is not available, or if the arg is set to `False` (the default), it will\n    cause an error.\n\n    The setting may also be supplied at an individual schema level.\n\n    Can be used as a decorator for a class to indicate that extra keys on the schema informed by the class are allowed,\n    as a global setting or as an annotation on a schema field.\n\n    !!! note\n\n        Only the first, highest priority annotation is used; thus if you pass a callback for *arg* it may not be called\n        if the #ExtraKeys setting you pass it to is overruled by another.\n    \"\"\"\n\n    def __init__(\n        self,\n        allow: bool = True,\n        recorder: \"t.Callable[[Context, t.Set[str]], t.Any] | None\" = None,\n        priority: Priority = Priority.NORMAL,\n    ) -&gt; None:\n        self.allow = allow\n        self.recorder = recorder\n        self.priority = priority\n\n    def inform(self, origin: \"Converter\", ctx: \"Context\", extra_keys: \"t.Set[str]\") -&gt; None:\n        from databind.core.converter import ConversionError\n\n        if self.allow is False:\n            raise ConversionError(origin, ctx, f\"encountered extra keys: {extra_keys}\")\n        elif self.recorder is not None:\n            self.recorder(ctx, extra_keys)\n</code></pre>"},{"location":"api/databind.core/#databind.core.Field","title":"Field  <code>dataclass</code>","text":"<p>Describes a field in a schema.</p> Source code in <code>databind/core/schema.py</code> <pre><code>@dataclasses.dataclass\nclass Field:\n    \"\"\"Describes a field in a schema.\"\"\"\n\n    #: The datatype of the field.\n    datatype: TypeHint\n\n    #: Whether the field is required to be present, if this is `False` and the field does not have a #default or\n    #: #default_factorty, the field value will not be passed to the schema constructor. Even if a #default or\n    #: #default_factory is present, if he field is required it must be present in the payload being deserialized.\n    required: bool = True\n\n    #: The default value for the field, if any.\n    default: t.Union[NotSet, t.Any] = NotSet.Value\n\n    #: The default value factory for the field, if any.\n    default_factory: t.Union[NotSet, t.Any] = NotSet.Value\n\n    #: Indicates whether the field is to be treated \"flat\". If the #datatype is a structured type that has fields of its\n    #: own, those fields should be treated as if expanded into the same level as this field.\n    flattened: bool = False\n\n    def has_default(self) -&gt; bool:\n        return self.default is not NotSet.Value or self.default_factory is not NotSet.Value\n\n    def get_default(self) -&gt; t.Any:\n        if self.default is not NotSet.Value:\n            return self.default\n        elif self.default_factory is not NotSet.Value:\n            return self.default_factory()\n        else:\n            raise RuntimeError(\"Field does not have a default value\")\n\n    @property\n    def aliases(self) -&gt; t.Tuple[str, ...]:\n        \"\"\"For convience, the aliases described in the #datatype#'s annotations are listed here. Do note however, that\n        during the conversion process, the #Alias setting should still be looked up through #Context.get_setting()\n        and this field should be ignored. It serves only a introspective purpose. Returns an empty tuple if no alias\n        setting is present in the type hint.\"\"\"\n\n        from databind.core.settings import Alias, get_annotation_setting\n\n        alias = get_annotation_setting(self.datatype, Alias)\n        return alias.aliases if alias else ()\n</code></pre>"},{"location":"api/databind.core/#databind.core.Field.aliases","title":"aliases  <code>property</code>","text":"<pre><code>aliases: Tuple[str, ...]\n</code></pre> <p>For convience, the aliases described in the #datatype#'s annotations are listed here. Do note however, that during the conversion process, the #Alias setting should still be looked up through #Context.get_setting() and this field should be ignored. It serves only a introspective purpose. Returns an empty tuple if no alias setting is present in the type hint.</p>"},{"location":"api/databind.core/#databind.core.Flattened","title":"Flattened  <code>dataclass</code>","text":"<p>             Bases: <code>BooleanSetting</code></p> <p>Indicates whether a field should be \"flattened\" by virtually expanding it's sub fields into the parent datastructure's serialized form.</p> <p>Example:</p> <pre><code>import typing\nfrom dataclasses import dataclass\nfrom databind.core.settings import Flattened\n\n@dataclass\nclass Inner:\n  a: int\n  b: str\n\n@dataclass\nclass Outter:\n  inner: typing.Annotated[Inner, Flattened()]\n  c: str\n</code></pre> <p>The <code>Outter</code> class in the example above may be deserialized, for example, from a JSON payload of the form <code>{\"a\": 0, \"b\": \"\", \"c\": \"\"}</code> as opposed to <code>{\"inner\": {\"a\": 0, \"b\": \"\"}, \"c\": \"\"}</code> due to the <code>Outter.inner</code> field's sub fields being expanded into <code>Outter</code>.</p> Source code in <code>databind/core/settings.py</code> <pre><code>class Flattened(BooleanSetting):\n    \"\"\"Indicates whether a field should be \"flattened\" by virtually expanding it's sub fields into the parent\n    datastructure's serialized form.\n\n    Example:\n\n    ```py\n    import typing\n    from dataclasses import dataclass\n    from databind.core.settings import Flattened\n\n    @dataclass\n    class Inner:\n      a: int\n      b: str\n\n    @dataclass\n    class Outter:\n      inner: typing.Annotated[Inner, Flattened()]\n      c: str\n    ```\n\n    The `Outter` class in the example above may be deserialized, for example, from a JSON payload of the form\n    `{\"a\": 0, \"b\": \"\", \"c\": \"\"}` as opposed to `{\"inner\": {\"a\": 0, \"b\": \"\"}, \"c\": \"\"}` due to the `Outter.inner`\n    field's sub fields being expanded into `Outter`.\n    \"\"\"\n</code></pre>"},{"location":"api/databind.core/#databind.core.Location","title":"Location  <code>dataclass</code>","text":"<p>Represents a location in a file.</p> Source code in <code>databind/core/context.py</code> <pre><code>@dataclasses.dataclass(frozen=True)\nclass Location:\n    \"\"\"Represents a location in a file.\"\"\"\n\n    #: The name of the file.\n    filename: t.Optional[str]\n\n    #: The line number in the file.\n    line: t.Optional[int]\n\n    #: The column number in the file.\n    column: t.Optional[int]\n\n    EMPTY: t.ClassVar[\"Location\"]\n</code></pre>"},{"location":"api/databind.core/#databind.core.Module","title":"Module","text":"<p>             Bases: <code>Converter</code></p> <p>A module is a collection of #Converter#s.</p> Source code in <code>databind/core/converter.py</code> <pre><code>class Module(Converter):\n    \"\"\"A module is a collection of #Converter#s.\"\"\"\n\n    def __init__(self, name: str) -&gt; None:\n        self.name = name\n        self.converters: t.List[Converter] = []\n\n    def __repr__(self) -&gt; str:\n        return f\"Module({self.name!r})\"\n\n    def register(self, converter: Converter, first: bool = False) -&gt; None:\n        assert isinstance(converter, Converter), converter\n        if first:\n            self.converters.insert(0, converter)\n        else:\n            self.converters.append(converter)\n\n    def get_converters(self, ctx: \"Context\") -&gt; t.Iterator[Converter]:\n        for converter in self.converters:\n            if isinstance(converter, Module):\n                yield from converter.get_converters(ctx)\n            else:\n                yield converter\n\n    def convert(self, ctx: \"Context\") -&gt; t.Any:\n        errors: t.List[t.Tuple[Converter, Exception]] = []\n        for converter in self.get_converters(ctx):\n            try:\n                return converter.convert(ctx)\n            except NotImplementedError:\n                pass\n            except ConversionError as exc:\n                errors.append((converter, exc))\n        if len(errors) == 1:\n            raise errors[0][1]\n        raise NoMatchingConverter(self, ctx, errors)\n</code></pre>"},{"location":"api/databind.core/#databind.core.NoMatchingConverter","title":"NoMatchingConverter","text":"<p>             Bases: <code>ConversionError</code></p> <p>If no converter matched to convert the value and datatype in the context.</p> Source code in <code>databind/core/converter.py</code> <pre><code>class NoMatchingConverter(ConversionError):\n    \"\"\"If no converter matched to convert the value and datatype in the context.\"\"\"\n\n    def __init__(self, origin: Converter, context: \"Context\", errors: \"t.List[t.Tuple[Converter, Exception]]\") -&gt; None:\n        super().__init__(\n            origin,\n            context,\n            f\"no {context.direction.name.lower()}r for `{context.datatype}` and payload of type \"\n            f\"`{type_repr(type(context.value))}`\",\n            errors,\n        )\n</code></pre>"},{"location":"api/databind.core/#databind.core.ObjectMapper","title":"ObjectMapper","text":"<p>             Bases: <code>Generic[T, U]</code></p> <p>The object mapper is responsible for dispatching the conversion process into a #Module.</p> <p>The type parameter T represents the deserialized type, while U represents the serialized type.</p> Source code in <code>databind/core/mapper.py</code> <pre><code>class ObjectMapper(t.Generic[T, U]):\n    \"\"\"The object mapper is responsible for dispatching the conversion process into a #Module.\n\n    The type parameter *T* represents the deserialized type, while *U* represents the serialized type.\n    \"\"\"\n\n    def __init__(self, settings: t.Optional[\"Settings\"] = None) -&gt; None:\n        from databind.core.converter import Module\n        from databind.core.settings import Settings\n\n        assert isinstance(settings, (type(None), Settings)), settings\n        self.module = Module(\"ObjectMapper.module\")\n        self.settings = settings or Settings()\n\n    def copy(self) -&gt; \"ObjectMapper[T, U]\":\n        new = type(self)(self.settings.copy())\n        new.module.converters.extend(self.module.converters)\n        return new\n\n    def convert(\n        self,\n        direction: \"Direction\",\n        value: t.Any,\n        datatype: \"TypeHint | t.Any\",\n        location: \"Location | None\" = None,\n        settings: \"SettingsProvider | t.List[Setting] | None\" = None,\n    ) -&gt; t.Any:\n        \"\"\"Convert a value according to the given datatype.\n\n        Arguments:\n          direction: The direction, i.e. either deserialization or serialization.\n          value: The value to convert.\n          datatype: The datatype. If not already a #TypeHint instance, it will be converted using #TypeHint().\n          location: The location of where *value* is coming from. Useful to specify to make debugging easier.\n          settings: A list of settings, in which case they will be treated as global settings in addition to the\n            mapper's #settings, or an entirely different #SettingsProvider instance (for which it is recommended that\n            it is taking the ObjectMapper's #settings into account, for example by passing them for the\n            #Settings.parent).\n\n        Raises:\n          ConversionError: For more generic errosr during the conversion process.\n          NoMatchingConverter: If at any point during the conversion a datatype was encountered for which no matching\n            converter was found.\n        \"\"\"\n\n        from databind.core.context import Context, Location\n        from databind.core.settings import Settings\n\n        if not isinstance(datatype, TypeHint):\n            datatype = TypeHint(datatype)\n        if isinstance(settings, list):\n            settings = Settings(self.settings, global_settings=settings)\n\n        context = Context(\n            parent=None,\n            direction=direction,\n            value=value,\n            datatype=datatype,\n            settings=settings or self.settings,\n            key=Context.ROOT,\n            location=location or Location.EMPTY,\n            convert_func=self.module.convert,\n        )\n\n        return context.convert()\n\n    def serialize(\n        self,\n        value: T,\n        datatype: \"TypeHint | t.Any\",\n        filename: \"str | None\" = None,\n        settings: \"SettingsProvider | t.List[Setting] | None\" = None,\n    ) -&gt; U:\n        \"\"\"Serialize *value* according to the its *datatype*.\"\"\"\n\n        from databind.core.context import Direction, Location\n\n        return t.cast(U, self.convert(Direction.SERIALIZE, value, datatype, Location(filename, None, None), settings))\n\n    def deserialize(\n        self,\n        value: U,\n        datatype: \"TypeHint | t.Any\",\n        filename: \"str | None\" = None,\n        settings: \"SettingsProvider | t.List[Setting] | None\" = None,\n    ) -&gt; T:\n        \"\"\"Deserialize *value* according to the its *datatype*.\"\"\"\n\n        from databind.core.context import Direction, Location\n\n        return t.cast(\n            T,\n            self.convert(Direction.DESERIALIZE, value, datatype, Location(filename, None, None), settings),\n        )\n</code></pre>"},{"location":"api/databind.core/#databind.core.ObjectMapper.__init__","title":"__init__","text":"<pre><code>__init__(settings: Optional[Settings] = None) -&gt; None\n</code></pre> Source code in <code>databind/core/mapper.py</code> <pre><code>def __init__(self, settings: t.Optional[\"Settings\"] = None) -&gt; None:\n    from databind.core.converter import Module\n    from databind.core.settings import Settings\n\n    assert isinstance(settings, (type(None), Settings)), settings\n    self.module = Module(\"ObjectMapper.module\")\n    self.settings = settings or Settings()\n</code></pre>"},{"location":"api/databind.core/#databind.core.ObjectMapper.convert","title":"convert","text":"<pre><code>convert(direction: Direction, value: Any, datatype: TypeHint | Any, location: Location | None = None, settings: SettingsProvider | List[Setting] | None = None) -&gt; Any\n</code></pre> <p>Convert a value according to the given datatype.</p> <p>Parameters:</p> Name Type Description Default <code>direction</code> <code>Direction</code> <p>The direction, i.e. either deserialization or serialization.</p> required <code>value</code> <code>Any</code> <p>The value to convert.</p> required <code>datatype</code> <code>TypeHint | Any</code> <p>The datatype. If not already a #TypeHint instance, it will be converted using #TypeHint().</p> required <code>location</code> <code>Location | None</code> <p>The location of where value is coming from. Useful to specify to make debugging easier.</p> <code>None</code> <code>settings</code> <code>SettingsProvider | List[Setting] | None</code> <p>A list of settings, in which case they will be treated as global settings in addition to the mapper's #settings, or an entirely different #SettingsProvider instance (for which it is recommended that it is taking the ObjectMapper's #settings into account, for example by passing them for the</p> <code>None</code> <p>Raises:</p> Type Description <code>ConversionError</code> <p>For more generic errosr during the conversion process.</p> <code>NoMatchingConverter</code> <p>If at any point during the conversion a datatype was encountered for which no matching converter was found.</p> Source code in <code>databind/core/mapper.py</code> <pre><code>def convert(\n    self,\n    direction: \"Direction\",\n    value: t.Any,\n    datatype: \"TypeHint | t.Any\",\n    location: \"Location | None\" = None,\n    settings: \"SettingsProvider | t.List[Setting] | None\" = None,\n) -&gt; t.Any:\n    \"\"\"Convert a value according to the given datatype.\n\n    Arguments:\n      direction: The direction, i.e. either deserialization or serialization.\n      value: The value to convert.\n      datatype: The datatype. If not already a #TypeHint instance, it will be converted using #TypeHint().\n      location: The location of where *value* is coming from. Useful to specify to make debugging easier.\n      settings: A list of settings, in which case they will be treated as global settings in addition to the\n        mapper's #settings, or an entirely different #SettingsProvider instance (for which it is recommended that\n        it is taking the ObjectMapper's #settings into account, for example by passing them for the\n        #Settings.parent).\n\n    Raises:\n      ConversionError: For more generic errosr during the conversion process.\n      NoMatchingConverter: If at any point during the conversion a datatype was encountered for which no matching\n        converter was found.\n    \"\"\"\n\n    from databind.core.context import Context, Location\n    from databind.core.settings import Settings\n\n    if not isinstance(datatype, TypeHint):\n        datatype = TypeHint(datatype)\n    if isinstance(settings, list):\n        settings = Settings(self.settings, global_settings=settings)\n\n    context = Context(\n        parent=None,\n        direction=direction,\n        value=value,\n        datatype=datatype,\n        settings=settings or self.settings,\n        key=Context.ROOT,\n        location=location or Location.EMPTY,\n        convert_func=self.module.convert,\n    )\n\n    return context.convert()\n</code></pre>"},{"location":"api/databind.core/#databind.core.ObjectMapper.convert--settingsparent","title":"Settings.parent).","text":""},{"location":"api/databind.core/#databind.core.ObjectMapper.deserialize","title":"deserialize","text":"<pre><code>deserialize(value: U, datatype: TypeHint | Any, filename: str | None = None, settings: SettingsProvider | List[Setting] | None = None) -&gt; T\n</code></pre> <p>Deserialize value according to the its datatype.</p> Source code in <code>databind/core/mapper.py</code> <pre><code>def deserialize(\n    self,\n    value: U,\n    datatype: \"TypeHint | t.Any\",\n    filename: \"str | None\" = None,\n    settings: \"SettingsProvider | t.List[Setting] | None\" = None,\n) -&gt; T:\n    \"\"\"Deserialize *value* according to the its *datatype*.\"\"\"\n\n    from databind.core.context import Direction, Location\n\n    return t.cast(\n        T,\n        self.convert(Direction.DESERIALIZE, value, datatype, Location(filename, None, None), settings),\n    )\n</code></pre>"},{"location":"api/databind.core/#databind.core.ObjectMapper.serialize","title":"serialize","text":"<pre><code>serialize(value: T, datatype: TypeHint | Any, filename: str | None = None, settings: SettingsProvider | List[Setting] | None = None) -&gt; U\n</code></pre> <p>Serialize value according to the its datatype.</p> Source code in <code>databind/core/mapper.py</code> <pre><code>def serialize(\n    self,\n    value: T,\n    datatype: \"TypeHint | t.Any\",\n    filename: \"str | None\" = None,\n    settings: \"SettingsProvider | t.List[Setting] | None\" = None,\n) -&gt; U:\n    \"\"\"Serialize *value* according to the its *datatype*.\"\"\"\n\n    from databind.core.context import Direction, Location\n\n    return t.cast(U, self.convert(Direction.SERIALIZE, value, datatype, Location(filename, None, None), settings))\n</code></pre>"},{"location":"api/databind.core/#databind.core.Precision","title":"Precision  <code>dataclass</code>","text":"<p>             Bases: <code>Setting</code></p> <p>A setting to describe the precision for #decimal.Decimal fields.</p> Source code in <code>databind/core/settings.py</code> <pre><code>@dataclasses.dataclass(frozen=True)\nclass Precision(Setting):\n    \"\"\"A setting to describe the precision for #decimal.Decimal fields.\"\"\"\n\n    prec: t.Optional[int] = None\n    rounding: t.Optional[str] = None\n    Emin: t.Optional[int] = None\n    Emax: t.Optional[int] = None\n    capitals: t.Optional[bool] = None\n    clamp: t.Optional[bool] = None\n    priority: Priority = Priority.NORMAL\n\n    def to_decimal_context(self) -&gt; decimal.Context:\n        return decimal.Context(\n            prec=self.prec,\n            rounding=self.rounding,\n            Emin=self.Emin,\n            Emax=self.Emax,\n            capitals=self.capitals,\n            clamp=self.clamp,\n        )\n</code></pre>"},{"location":"api/databind.core/#databind.core.Priority","title":"Priority","text":"<p>             Bases: <code>IntEnum</code></p> <p>The priority for settings determines their order in the presence of multiple conflicting settings. Settings should default to using the #NORMAL priority. The other priorities are used to either prevent overriding a field setting globally or to enforce overriding of local field settings globally using #Settings.</p> Source code in <code>databind/core/settings.py</code> <pre><code>class Priority(enum.IntEnum):\n    \"\"\"The priority for settings determines their order in the presence of multiple conflicting settings. Settings\n    should default to using the #NORMAL priority. The other priorities are used to either prevent overriding a field\n    setting globally or to enforce overriding of local field settings globally using #Settings.\"\"\"\n\n    LOW = 0\n    NORMAL = 1\n    HIGH = 2\n    ULTIMATE = 3\n</code></pre>"},{"location":"api/databind.core/#databind.core.Remainder","title":"Remainder  <code>dataclass</code>","text":"<p>             Bases: <code>BooleanSetting</code></p> <p>This setting can be used to indicate on a field of a schema that is of a mapping type that it consumes any extra keys that are not otherwise understood by the schema. Note that there can only be a maximum of 1 remainder field in the same schema.</p> Source code in <code>databind/core/settings.py</code> <pre><code>class Remainder(BooleanSetting):\n    \"\"\"This setting can be used to indicate on a field of a schema that is of a mapping type that it consumes any\n    extra keys that are not otherwise understood by the schema. Note that there can only be a maximum of 1 remainder\n    field in the same schema.\"\"\"\n</code></pre>"},{"location":"api/databind.core/#databind.core.Required","title":"Required  <code>dataclass</code>","text":"<p>             Bases: <code>BooleanSetting</code></p> <p>Indicates whether a field is required during deserialization, even if it's type specifies that it is an optional field.</p> <p>Example:</p> <pre><code>import typing\nfrom dataclasses import dataclass\nfrom databind.core.settings import Required\n\n@dataclass\nclass MyClass:\n  my_field: typing.Annotated[typing.Optional[int], Required()]\n</code></pre> Source code in <code>databind/core/settings.py</code> <pre><code>class Required(BooleanSetting):\n    \"\"\"Indicates whether a field is required during deserialization, even if it's type specifies that it is an\n    optional field.\n\n    Example:\n\n    ```py\n    import typing\n    from dataclasses import dataclass\n    from databind.core.settings import Required\n\n    @dataclass\n    class MyClass:\n      my_field: typing.Annotated[typing.Optional[int], Required()]\n    ```\n    \"\"\"\n</code></pre>"},{"location":"api/databind.core/#databind.core.Schema","title":"Schema  <code>dataclass</code>","text":"<p>A #Schema describes a set of fields with a name and datatype.</p> Source code in <code>databind/core/schema.py</code> <pre><code>@dataclasses.dataclass\nclass Schema:\n    \"\"\"A #Schema describes a set of fields with a name and datatype.\"\"\"\n\n    #: A dictionary that maps the field descriptions in the schema. The key is the name of the field in code. Given an\n    #: instance of an object that complies to a given #Schema, this is the name by which the value of the field should\n    #: be read using attribute lookup.\n    fields: t.Dict[str, Field]\n\n    #: A function that constructs an instance of a Python object that this schema represents given a dictionary as\n    #: keyword arguments of the deserialized field values. Fields that are not present in the source payload and a that\n    #: do not have a default value will not be present in the passed dictionary.\n    constructor: \"Constructor\"\n\n    #: The underlying native Python type associated with the schema.\n    type: type\n\n    #: Annotation metadata that goes with the schema, possibly derived from a #AnnotatedTypeHint hint or the underlying\n    #: Python type object.\n    annotations: t.List[t.Any] = dataclasses.field(default_factory=list)\n</code></pre>"},{"location":"api/databind.core/#databind.core.SerializeDefaults","title":"SerializeDefaults  <code>dataclass</code>","text":"<p>             Bases: <code>BooleanSetting</code></p> <p>Control whether default values are to be encoded in the serialized form of a structure. The default behaviour is up to the serializer implementation, though we consider it good practices to include values that match the default value of a field by default. However, using the setting defaults to #enabled having a value of <code>True</code> due to how the name of the setting appears assertive of the fact that the instance indicates the setting is enabled.</p> Source code in <code>databind/core/settings.py</code> <pre><code>class SerializeDefaults(BooleanSetting):\n    \"\"\"Control whether default values are to be encoded in the serialized form of a structure. The default behaviour\n    is up to the serializer implementation, though we consider it good practices to include values that match the\n    default value of a field by default. However, using the setting defaults to #enabled having a value of `True` due\n    to how the name of the setting appears assertive of the fact that the instance indicates the setting is enabled.\"\"\"\n</code></pre>"},{"location":"api/databind.core/#databind.core.Setting","title":"Setting","text":"<p>Base class for types of which instances represent a setting to be taken into account during data conversion. Every setting has a priority that is used to construct and order or to determine the single setting to use in the presence of multiple instances of the same setting type being present.</p> <p>Settings are usually attached to dataclass fields using #typing.Annotated, or added to a #Settings object for applying the setting globally, but some subclasses may support being used as decorators to attach the setting to a type object. Such settings would registers themselves under the <code>__databind_settings__</code> attribute (created if it does not exist) such that it can be picked up when introspected by a converter. Such #Setting subclasses should inherit from #DecoratorSetting instead.</p> Source code in <code>databind/core/settings.py</code> <pre><code>class Setting:\n    \"\"\"Base class for types of which instances represent a setting to be taken into account during data conversion.\n    Every setting has a priority that is used to construct and order or to determine the single setting to use in\n    the presence of multiple instances of the same setting type being present.\n\n    Settings are usually attached to dataclass fields using #typing.Annotated, or added to a #Settings object for\n    applying the setting globally, but some subclasses may support being used as decorators to attach the setting\n    to a type object. Such settings would registers themselves under the `__databind_settings__` attribute (created\n    if it does not exist) such that it can be picked up when introspected by a converter. Such #Setting subclasses\n    should inherit from #DecoratorSetting instead.\"\"\"\n\n    priority: Priority = Priority.NORMAL\n\n    def __init__(self) -&gt; None:\n        if type(self) is Setting:\n            raise TypeError(\"Setting cannot be directly instantiated\")\n</code></pre>"},{"location":"api/databind.core/#databind.core.Settings","title":"Settings","text":"<p>             Bases: <code>SettingsProvider</code></p> <p>This class is used as a container for other objects that serve as a provider of settings that may taken into account during data conversion. Objects that provide settings are instances of #Setting subclasses, such as</p>"},{"location":"api/databind.core/#databind.core.Settings--fieldalias-or-dateformat","title":"FieldAlias or #DateFormat.","text":"<p>Depending on the type of setting, they may be taken into account if present on a field of a dataclass, or globally from an instance of the #Settings class that is passed to the #ObjectMapper, or both. Which settings are recognized and considered depends also on the implementation of the converter(s) being used.</p> <p>The #Settings class provides capabilities to supply global settings, as well as supplying settings conditionally based on the type that is being looked at by the #ObjectMapper at the given point in time.</p> <p>Example:</p> <pre><code>from databind.core.settings import DateFormat, Priority, Settings, Strict\nsettings = Settings()\nsettings.add_global(DateFormat('.ISO_8601', priority=Priority.HIGH))\nsettings.add_local(int, Strict(false))\n</code></pre> Source code in <code>databind/core/settings.py</code> <pre><code>class Settings(SettingsProvider):\n    \"\"\"This class is used as a container for other objects that serve as a provider of settings that may taken into\n    account during data conversion. Objects that provide settings are instances of #Setting subclasses, such as\n    #FieldAlias or #DateFormat.\n\n    Depending on the type of setting, they may be taken into account if present on a field of a dataclass, or globally\n    from an instance of the #Settings class that is passed to the #ObjectMapper, or both. Which settings are recognized\n    and considered depends also on the implementation of the converter(s) being used.\n\n    The #Settings class provides capabilities to supply global settings, as well as supplying settings conditionally\n    based on the type that is being looked at by the #ObjectMapper at the given point in time.\n\n    Example:\n\n    ```py\n    from databind.core.settings import DateFormat, Priority, Settings, Strict\n    settings = Settings()\n    settings.add_global(DateFormat('.ISO_8601', priority=Priority.HIGH))\n    settings.add_local(int, Strict(false))\n    ```\n    \"\"\"\n\n    def __init__(\n        self, parent: t.Optional[SettingsProvider] = None, global_settings: t.Optional[t.List[\"Setting\"]] = None\n    ) -&gt; None:\n        self.parent = parent\n        self.global_settings: t.List[Setting] = list(global_settings) if global_settings else []\n        self.local_settings: t.Dict[type, t.List[Setting]] = {}\n        self.providers: t.List[t.Callable[[Context], t.List[Setting]]] = []\n\n    def add_global(self, setting: \"Setting\") -&gt; None:\n        \"\"\"Add a global setting.\"\"\"\n\n        self.global_settings.append(setting)\n\n    def add_local(self, type_: type, setting: \"Setting\") -&gt; None:\n        \"\"\"Add a setting locally for a particular Python type. If that Python type is encountered, the settings are\n        combined with any other settings that are found for the type.\"\"\"\n\n        self.local_settings.setdefault(type_, []).append(setting)\n\n    def add_conditional(self, predicate: t.Callable[[\"Context\"], bool], setting: \"Setting\") -&gt; None:\n        \"\"\"Adds a setting conditional on the given *predicate*.\"\"\"\n\n        def _provider(context: Context) -&gt; t.List[Setting]:\n            if predicate(context):\n                return [setting]\n            return []\n\n        self.providers.append(_provider)\n\n    def add_provider(self, provider: t.Callable[[\"Context\"], t.List[\"Setting\"]]) -&gt; None:\n        \"\"\"Add a provider callback that is invoked for every conversion context to provide additional settings that\n        the subsequent converter should have access to.\"\"\"\n\n        self.providers.append(provider)\n\n    def copy(self) -&gt; \"Settings\":\n        new = type(self)(self.parent, self.global_settings)\n        new.local_settings = {k: list(v) for k, v in self.local_settings.items()}\n        new.providers = list(self.providers)\n        return new\n\n    # SettingsProvider\n\n    def get_setting(self, context: \"Context\", setting_type: t.Type[T_Setting]) -&gt; \"T_Setting | None\":\n        \"\"\"Resolves the highest priority instance of the given setting type relevant to the current context. The places\n        that the setting is looked for are, in order:\n\n        1. If the context's datatype is #AnnotatedTypeHint, look for it in the #AnnotatedTypeHint.metadata. Otherwise,\n           use the wrapped type in the following steps.\n        2. If the datatype is a #ClassTypeHint, look for it as a class setting, then subsequently in the settings added\n           with #add_local().\n        3. Check the setting providers added with #add_provider() or #add_conditional().\n        4. Look for it in the global settings.\n        5. Delegate to the #parent settings provider (if any).\n\n        If multiple settings are find using any of these steps, the setting with the highest priority among the\n        settings is returned. If multiple settings have the same priority, the setting found first via the above order\n        is returned.\n        \"\"\"\n\n        from nr.stream import Stream\n\n        def _all_settings() -&gt; t.Iterator[t.Any]:\n            datatype = context.datatype\n            if isinstance(datatype, AnnotatedTypeHint):\n                yield from (s for s in datatype.metadata if isinstance(s, setting_type))\n                datatype = datatype[0]\n            if isinstance(datatype, ClassTypeHint):\n                yield from get_class_settings(datatype.type, setting_type)  # type: ignore[type-var]\n                yield from self.local_settings.get(datatype.type, [])\n            for provider in self.providers:\n                yield from provider(context)\n            yield from self.global_settings\n            if self.parent:\n                setting = self.parent.get_setting(context, setting_type)\n                if setting is not None:\n                    yield setting\n\n        return get_highest_setting(Stream(_all_settings()).of_type(setting_type))\n</code></pre>"},{"location":"api/databind.core/#databind.core.Settings.add_conditional","title":"add_conditional","text":"<pre><code>add_conditional(predicate: Callable[[Context], bool], setting: Setting) -&gt; None\n</code></pre> <p>Adds a setting conditional on the given predicate.</p> Source code in <code>databind/core/settings.py</code> <pre><code>def add_conditional(self, predicate: t.Callable[[\"Context\"], bool], setting: \"Setting\") -&gt; None:\n    \"\"\"Adds a setting conditional on the given *predicate*.\"\"\"\n\n    def _provider(context: Context) -&gt; t.List[Setting]:\n        if predicate(context):\n            return [setting]\n        return []\n\n    self.providers.append(_provider)\n</code></pre>"},{"location":"api/databind.core/#databind.core.Settings.add_global","title":"add_global","text":"<pre><code>add_global(setting: Setting) -&gt; None\n</code></pre> <p>Add a global setting.</p> Source code in <code>databind/core/settings.py</code> <pre><code>def add_global(self, setting: \"Setting\") -&gt; None:\n    \"\"\"Add a global setting.\"\"\"\n\n    self.global_settings.append(setting)\n</code></pre>"},{"location":"api/databind.core/#databind.core.Settings.add_local","title":"add_local","text":"<pre><code>add_local(type_: type, setting: Setting) -&gt; None\n</code></pre> <p>Add a setting locally for a particular Python type. If that Python type is encountered, the settings are combined with any other settings that are found for the type.</p> Source code in <code>databind/core/settings.py</code> <pre><code>def add_local(self, type_: type, setting: \"Setting\") -&gt; None:\n    \"\"\"Add a setting locally for a particular Python type. If that Python type is encountered, the settings are\n    combined with any other settings that are found for the type.\"\"\"\n\n    self.local_settings.setdefault(type_, []).append(setting)\n</code></pre>"},{"location":"api/databind.core/#databind.core.Settings.add_provider","title":"add_provider","text":"<pre><code>add_provider(provider: Callable[[Context], List[Setting]]) -&gt; None\n</code></pre> <p>Add a provider callback that is invoked for every conversion context to provide additional settings that the subsequent converter should have access to.</p> Source code in <code>databind/core/settings.py</code> <pre><code>def add_provider(self, provider: t.Callable[[\"Context\"], t.List[\"Setting\"]]) -&gt; None:\n    \"\"\"Add a provider callback that is invoked for every conversion context to provide additional settings that\n    the subsequent converter should have access to.\"\"\"\n\n    self.providers.append(provider)\n</code></pre>"},{"location":"api/databind.core/#databind.core.Settings.get_setting","title":"get_setting","text":"<pre><code>get_setting(context: Context, setting_type: Type[T_Setting]) -&gt; T_Setting | None\n</code></pre> <p>Resolves the highest priority instance of the given setting type relevant to the current context. The places that the setting is looked for are, in order:</p> <ol> <li>If the context's datatype is #AnnotatedTypeHint, look for it in the #AnnotatedTypeHint.metadata. Otherwise,    use the wrapped type in the following steps.</li> <li>If the datatype is a #ClassTypeHint, look for it as a class setting, then subsequently in the settings added    with #add_local().</li> <li>Check the setting providers added with #add_provider() or #add_conditional().</li> <li>Look for it in the global settings.</li> <li>Delegate to the #parent settings provider (if any).</li> </ol> <p>If multiple settings are find using any of these steps, the setting with the highest priority among the settings is returned. If multiple settings have the same priority, the setting found first via the above order is returned.</p> Source code in <code>databind/core/settings.py</code> <pre><code>def get_setting(self, context: \"Context\", setting_type: t.Type[T_Setting]) -&gt; \"T_Setting | None\":\n    \"\"\"Resolves the highest priority instance of the given setting type relevant to the current context. The places\n    that the setting is looked for are, in order:\n\n    1. If the context's datatype is #AnnotatedTypeHint, look for it in the #AnnotatedTypeHint.metadata. Otherwise,\n       use the wrapped type in the following steps.\n    2. If the datatype is a #ClassTypeHint, look for it as a class setting, then subsequently in the settings added\n       with #add_local().\n    3. Check the setting providers added with #add_provider() or #add_conditional().\n    4. Look for it in the global settings.\n    5. Delegate to the #parent settings provider (if any).\n\n    If multiple settings are find using any of these steps, the setting with the highest priority among the\n    settings is returned. If multiple settings have the same priority, the setting found first via the above order\n    is returned.\n    \"\"\"\n\n    from nr.stream import Stream\n\n    def _all_settings() -&gt; t.Iterator[t.Any]:\n        datatype = context.datatype\n        if isinstance(datatype, AnnotatedTypeHint):\n            yield from (s for s in datatype.metadata if isinstance(s, setting_type))\n            datatype = datatype[0]\n        if isinstance(datatype, ClassTypeHint):\n            yield from get_class_settings(datatype.type, setting_type)  # type: ignore[type-var]\n            yield from self.local_settings.get(datatype.type, [])\n        for provider in self.providers:\n            yield from provider(context)\n        yield from self.global_settings\n        if self.parent:\n            setting = self.parent.get_setting(context, setting_type)\n            if setting is not None:\n                yield setting\n\n    return get_highest_setting(Stream(_all_settings()).of_type(setting_type))\n</code></pre>"},{"location":"api/databind.core/#databind.core.SettingsProvider","title":"SettingsProvider","text":"<p>             Bases: <code>ABC</code></p> <p>Interface for providing settings.</p> Source code in <code>databind/core/settings.py</code> <pre><code>class SettingsProvider(abc.ABC):\n    \"\"\"Interface for providing settings.\"\"\"\n\n    def get_setting(self, context: \"Context\", setting_type: \"t.Type[T_Setting]\") -&gt; \"T_Setting | None\":\n        ...\n</code></pre>"},{"location":"api/databind.core/#databind.core.Strict","title":"Strict  <code>dataclass</code>","text":"<p>             Bases: <code>BooleanSetting</code></p> <p>Enable strict conversion of the field during conversion (this should be the default for converters unless some maybe available option to affect the strictness in a converter is changed). This setting should particularly affect only loss-less type conversions (such as <code>int</code> to <code>string</code> and the reverse being allowed when strict handling is disabled).</p> Source code in <code>databind/core/settings.py</code> <pre><code>class Strict(BooleanSetting):\n    \"\"\"Enable strict conversion of the field during conversion (this should be the default for converters unless\n    some maybe available option to affect the strictness in a converter is changed). This setting should particularly\n    affect only loss-less type conversions (such as `int` to `string` and the reverse being allowed when strict\n    handling is disabled).\"\"\"\n</code></pre>"},{"location":"api/databind.core/#databind.core.Union","title":"Union  <code>dataclass</code>","text":"<p>             Bases: <code>ClassDecoratorSetting</code></p> <p>A setting that decorates a class or can be attached to the #typing.Annotated metadata of a #typing.Union type hint to specify that the type should be regarded as a union of more than one types. Which concrete type is to be used at the point of deserialization is usually clarified through a discriminator key. Unions may be of various styles that dictate how the discriminator key and the remaining fields are to be stored or read from.</p> <p>For serialiazation, the type of the Python value should inform the converter about which member of the union is being used. If the a union definition has multiple type IDs mapping to the same Python type, the behaviour is entirely up to the converter (an adequate resolution may be to pick the first matching type ID and ignore the remaining matches).</p> <p>Note</p> <p>The the examples for the different styles below, <code>\"type\"</code> is a stand-in for the value of the #discriminator_key and <code>...</code> serves as a stand-in for the remaining fields of the type that is represented by the discriminator.</p> Source code in <code>databind/core/settings.py</code> <pre><code>@dataclasses.dataclass\nclass Union(ClassDecoratorSetting):\n    \"\"\"A setting that decorates a class or can be attached to the #typing.Annotated metadata of a #typing.Union\n    type hint to specify that the type should be regarded as a union of more than one types. Which concrete type\n    is to be used at the point of deserialization is usually clarified through a discriminator key. Unions may be\n    of various styles that dictate how the discriminator key and the remaining fields are to be stored or read\n    from.\n\n    For serialiazation, the type of the Python value should inform the converter about which member of the union\n    is being used. If the a union definition has multiple type IDs mapping to the same Python type, the behaviour\n    is entirely up to the converter (an adequate resolution may be to pick the first matching type ID and ignore\n    the remaining matches).\n\n    !!! note\n\n        The the examples for the different styles below, `\"type\"` is a stand-in for the value of the #discriminator_key\n        and `...` serves as a stand-in for the remaining fields of the type that is represented by the discriminator.\n    \"\"\"\n\n    #: The nested style in JSON equivalent is best described as `{\"type\": \"&lt;typeid&gt;\", \"&lt;typeid&gt;\": { ... }}`.\n    NESTED: t.ClassVar = \"nested\"\n\n    #: The flat style in JSON equivalent is best described as `{\"type\": \"&lt;typeid&gt;\", ... }`.\n    FLAT: t.ClassVar = \"flat\"\n\n    #: The keyed style in JSON equivalent is best described as `{\"&lt;typeid&gt;\": { ... }}`.\n    KEYED: t.ClassVar = \"keyed\"\n\n    #: The \"best match\" style attempts to deserialize the payload in an implementation-defined order and return\n    #: the first or best succeeding result. No discriminator key is used.\n    BEST_MATCH: t.ClassVar = \"best_match\"\n\n    #: The subtypes of the union as an implementation of the #UnionMembers interface. When constructing the #Union\n    #: setting, a dictionary may be passed in place of a #UnionMembers implementation, or a list of #UnionMembers\n    #: to chain them together. Te constructor will also accept a string that is either `\"&lt;import&gt;\"`, which will\n    #: be converted to an #ImportUnionMembers handler, or a string formatted as `\"!&lt;entrypoint&gt;\"`, which will be\n    #: converted to an #EntrypointUnionMembers handler.\n    members: \"UnionMembers\"\n\n    #: The style of the union. This should be one of #NESTED, #FLAT, #KEYED or #BEST_MATCH. The default is #NESTED.\n    style: str = NESTED\n\n    #: The discriminator key to use, if valid for the #style. Defaults to `\"type\"`.\n    discriminator_key: str = \"type\"\n\n    #: The key to use when looking up the fields for the member type. Only used with the #NESTED style. If not set,\n    #: the union member's type ID is used as the key.\n    nesting_key: t.Optional[str] = None\n\n    def __init__(\n        self,\n        members: t.Union[\n            \"UnionMembers\",\n            \"StaticUnionMembers._MembersMappingType\",\n            \"t.List[UnionMembers | str | StaticUnionMembers._MembersMappingType]\",\n            str,\n            None,\n        ] = None,\n        style: str = NESTED,\n        discriminator_key: str = \"type\",\n        nesting_key: t.Optional[str] = None,\n    ) -&gt; None:\n        def _convert_handler(handler: \"UnionMembers | StaticUnionMembers._MembersMappingType | str\") -&gt; \"UnionMembers\":\n            if isinstance(handler, t.Mapping) or handler is None:\n                from databind.core.union import StaticUnionMembers\n\n                return StaticUnionMembers(dict(handler) or {})\n            elif isinstance(handler, str):\n                if handler == \"&lt;import&gt;\":\n                    return Union.import_()\n                elif handler.startswith(\"!\"):\n                    return Union.entrypoint(handler[1:])\n                raise ValueError(f\"invalid union members string specified: {handler!r}\")\n            return handler\n\n        if isinstance(members, list):\n            from databind.core.union import ChainUnionMembers\n\n            members = ChainUnionMembers(*(_convert_handler(x) for x in members))\n        elif members is None:\n            members = _convert_handler({})\n        else:\n            members = _convert_handler(members)\n\n        self.members = members\n        self.style = style\n        self.discriminator_key = discriminator_key\n        self.nesting_key = nesting_key\n\n    def __hash__(self) -&gt; int:\n        return id(self)  # Needs to be hashable for Annotated[...] in Python 3.6\n\n    @staticmethod\n    def register(extends: type, name: t.Optional[str] = None) -&gt; t.Callable[[t.Type[T]], t.Type[T]]:\n        \"\"\"A convenience method to use as a decorator for classes that should be registered as members of a #Union\n        setting that is attached to the type *extends*. The #Union setting on *extends* must have a #StaticUnionMembers\n        #members object. The decorated class must also be a subclass of *extends*.\n\n        Example:\n\n        ```py\n        import abc\n        import dataclasses\n        from databind.core.settings import Union\n\n        @Union()\n        class MyInterface(abc.ABC):\n          # ...\n          pass\n\n        @dataclasses.dataclass\n        @Union.register(MyInterface, 'some')\n        class SomeImplementation(MyInterface):\n          # ...\n          pass\n        ```\n        \"\"\"\n\n        from databind.core.union import StaticUnionMembers\n\n        check_instance_of(extends, type)\n        inst = check_not_none(\n            get_class_setting(extends, Union), lambda: f\"{extends.__name__} is not annotated with @union\"\n        )\n\n        members = check_instance_of(inst.members, StaticUnionMembers)\n\n        def _decorator(subtype: t.Type[T]) -&gt; t.Type[T]:\n            check_instance_of(subtype, type)\n            check_subclass_of(subtype, extends)\n            return members.register(name)(subtype)\n\n        return _decorator\n\n    @staticmethod\n    def entrypoint(group: str) -&gt; \"EntrypointUnionMembers\":\n        from databind.core.union import EntrypointUnionMembers\n\n        return EntrypointUnionMembers(group)\n\n    @staticmethod\n    def import_() -&gt; \"ImportUnionMembers\":\n        from databind.core.union import ImportUnionMembers\n\n        return ImportUnionMembers()\n</code></pre>"},{"location":"api/databind.core/#databind.core.Union.__init__","title":"__init__","text":"<pre><code>__init__(members: Union[UnionMembers, _MembersMappingType, List[UnionMembers | str | _MembersMappingType], str, None] = None, style: str = NESTED, discriminator_key: str = 'type', nesting_key: Optional[str] = None) -&gt; None\n</code></pre> Source code in <code>databind/core/settings.py</code> <pre><code>def __init__(\n    self,\n    members: t.Union[\n        \"UnionMembers\",\n        \"StaticUnionMembers._MembersMappingType\",\n        \"t.List[UnionMembers | str | StaticUnionMembers._MembersMappingType]\",\n        str,\n        None,\n    ] = None,\n    style: str = NESTED,\n    discriminator_key: str = \"type\",\n    nesting_key: t.Optional[str] = None,\n) -&gt; None:\n    def _convert_handler(handler: \"UnionMembers | StaticUnionMembers._MembersMappingType | str\") -&gt; \"UnionMembers\":\n        if isinstance(handler, t.Mapping) or handler is None:\n            from databind.core.union import StaticUnionMembers\n\n            return StaticUnionMembers(dict(handler) or {})\n        elif isinstance(handler, str):\n            if handler == \"&lt;import&gt;\":\n                return Union.import_()\n            elif handler.startswith(\"!\"):\n                return Union.entrypoint(handler[1:])\n            raise ValueError(f\"invalid union members string specified: {handler!r}\")\n        return handler\n\n    if isinstance(members, list):\n        from databind.core.union import ChainUnionMembers\n\n        members = ChainUnionMembers(*(_convert_handler(x) for x in members))\n    elif members is None:\n        members = _convert_handler({})\n    else:\n        members = _convert_handler(members)\n\n    self.members = members\n    self.style = style\n    self.discriminator_key = discriminator_key\n    self.nesting_key = nesting_key\n</code></pre>"},{"location":"api/databind.core/#databind.core.Union.register","title":"register  <code>staticmethod</code>","text":"<pre><code>register(extends: type, name: Optional[str] = None) -&gt; Callable[[Type[T]], Type[T]]\n</code></pre> <p>A convenience method to use as a decorator for classes that should be registered as members of a #Union setting that is attached to the type extends. The #Union setting on extends must have a #StaticUnionMembers</p>"},{"location":"api/databind.core/#databind.core.Union.register--members-object-the-decorated-class-must-also-be-a-subclass-of-extends","title":"members object. The decorated class must also be a subclass of extends.","text":"<p>Example:</p> <pre><code>import abc\nimport dataclasses\nfrom databind.core.settings import Union\n\n@Union()\nclass MyInterface(abc.ABC):\n  # ...\n  pass\n\n@dataclasses.dataclass\n@Union.register(MyInterface, 'some')\nclass SomeImplementation(MyInterface):\n  # ...\n  pass\n</code></pre> Source code in <code>databind/core/settings.py</code> <pre><code>@staticmethod\ndef register(extends: type, name: t.Optional[str] = None) -&gt; t.Callable[[t.Type[T]], t.Type[T]]:\n    \"\"\"A convenience method to use as a decorator for classes that should be registered as members of a #Union\n    setting that is attached to the type *extends*. The #Union setting on *extends* must have a #StaticUnionMembers\n    #members object. The decorated class must also be a subclass of *extends*.\n\n    Example:\n\n    ```py\n    import abc\n    import dataclasses\n    from databind.core.settings import Union\n\n    @Union()\n    class MyInterface(abc.ABC):\n      # ...\n      pass\n\n    @dataclasses.dataclass\n    @Union.register(MyInterface, 'some')\n    class SomeImplementation(MyInterface):\n      # ...\n      pass\n    ```\n    \"\"\"\n\n    from databind.core.union import StaticUnionMembers\n\n    check_instance_of(extends, type)\n    inst = check_not_none(\n        get_class_setting(extends, Union), lambda: f\"{extends.__name__} is not annotated with @union\"\n    )\n\n    members = check_instance_of(inst.members, StaticUnionMembers)\n\n    def _decorator(subtype: t.Type[T]) -&gt; t.Type[T]:\n        check_instance_of(subtype, type)\n        check_subclass_of(subtype, extends)\n        return members.register(name)(subtype)\n\n    return _decorator\n</code></pre>"},{"location":"api/databind.core/#databind.core.convert_dataclass_to_schema","title":"convert_dataclass_to_schema","text":"<pre><code>convert_dataclass_to_schema(dataclass_type: Union[type, GenericAlias, ClassTypeHint]) -&gt; Schema\n</code></pre> <p>Converts a Python class that is decorated with #dataclasses.dataclass() to a Schema.</p> <p>The function will respect the #Required setting if it is present in a field's datatype if, and only if, the setting occurs in the root type hint, which must be a #typing.Annotated hint.</p> <p>Parameters:</p> Name Type Description Default <code>dataclass_type</code> <code>Union[type, GenericAlias, ClassTypeHint]</code> <p>A Python type that is a dataclass, or a generic alias of a dataclass.</p> required <p>Returns:   A schema that represents the dataclass. If a generic alias was passed, fields of which the type hint contained   type parameters will have their type parameters substituted with the respective arguments present in the alias.</p> <p>Example:</p> <pre><code>import dataclasses\nfrom typing import Generic, TypeVar\nfrom typeapi import TypeHint\nfrom databind.core.schema import convert_dataclass_to_schema, Field, Schema\nT = TypeVar('T')\n@dataclasses.dataclass\nclass A(Generic[T]):\n  a: T\nassert convert_dataclass_to_schema(A[int]) == Schema({'a': Field(TypeHint(int))}, A)\n</code></pre> Source code in <code>databind/core/schema.py</code> <pre><code>def convert_dataclass_to_schema(dataclass_type: t.Union[type, GenericAlias, ClassTypeHint]) -&gt; Schema:\n    \"\"\"Converts a Python class that is decorated with #dataclasses.dataclass() to a Schema.\n\n    The function will respect the #Required setting if it is present in a field's datatype if,\n    and only if, the setting occurs in the root type hint, which must be a #typing.Annotated hint.\n\n    Arguments:\n      dataclass_type: A Python type that is a dataclass, or a generic alias of a dataclass.\n    Returns:\n      A schema that represents the dataclass. If a generic alias was passed, fields of which the type hint contained\n      type parameters will have their type parameters substituted with the respective arguments present in the alias.\n\n    Example:\n\n    ```py\n    import dataclasses\n    from typing import Generic, TypeVar\n    from typeapi import TypeHint\n    from databind.core.schema import convert_dataclass_to_schema, Field, Schema\n    T = TypeVar('T')\n    @dataclasses.dataclass\n    class A(Generic[T]):\n      a: T\n    assert convert_dataclass_to_schema(A[int]) == Schema({'a': Field(TypeHint(int))}, A)\n    ```\n    \"\"\"\n\n    from dataclasses import MISSING\n\n    hint: ClassTypeHint\n    if isinstance(dataclass_type, ClassTypeHint):\n        hint = dataclass_type\n    else:\n        hint = TypeHint(dataclass_type)  # type: ignore[assignment]\n        assert isinstance(hint, ClassTypeHint), hint\n\n    dataclass_type = hint.type\n    assert isinstance(dataclass_type, type), repr(dataclass_type)\n    assert dataclasses.is_dataclass(\n        dataclass_type\n    ), f\"expected a @dataclass type, but {type_repr(dataclass_type)} is not such a type\"\n\n    # Figure out which field is defined on which dataclass in the class hierarchy.\n    # This is important because we need to use the correct context when evaluating\n    # forward references in field annotations; we can't just use the target\n    # dataclass if it was defined in a different module.\n    field_origin: t.Dict[str, type] = {}\n    base_queue = [hint.type]\n    while base_queue:\n        base_type = base_queue.pop(0)\n        if dataclasses.is_dataclass(base_type):\n            annotations = get_annotations(base_type)\n            for field in dataclasses.fields(base_type):\n                if field.name in annotations and field.name not in field_origin:\n                    field_origin[field.name] = base_type\n        base_queue += base_type.__bases__\n\n    # Retrieve the context in which type hints from each field origin type need to be\n    # evaluated.\n    eval_context_by_type: t.Dict[type, t.Mapping[str, t.Any]] = {\n        type_: vars(sys.modules[type_.__module__]) for type_ in set(field_origin.values())\n    }\n\n    # Collect the members from the dataclass and its base classes.\n    queue = [hint]\n    fields: t.Dict[str, Field] = {}\n    while queue:\n        hint = queue.pop(0)\n        parameter_map = hint.get_parameter_map()\n\n        if hint.type in eval_context_by_type:\n            # Make sure forward references are resolved.\n            hint = hint.evaluate(eval_context_by_type[hint.type])  # type: ignore[assignment]\n            assert isinstance(hint, ClassTypeHint)\n\n            for field in dataclasses.fields(hint.type):\n                if not field.init:\n                    # If we cannot initialize the field in the constructor, we should also\n                    # exclude it from the definition of the type for de-/serializing.\n                    continue\n                if field.name in fields:\n                    # Subclasses override their parent's fields.\n                    continue\n                if field_origin[field.name] != hint.type:\n                    # If this field does not belong to the current type\n                    continue\n\n                field_hint = TypeHint(field.type, field_origin[field.name]).evaluate().parameterize(parameter_map)\n\n                # NOTE(NiklasRosenstein): In Python 3.6, Mypy complains about \"Callable does not accept self argument\",\n                #       but we also cannot ignore it because of warn_unused_ignores.\n                _field_default_factory = getattr(field, \"default_factory\")\n\n                default = NotSet.Value if field.default == MISSING else field.default\n                default_factory = NotSet.Value if _field_default_factory == MISSING else _field_default_factory\n                has_default = default != NotSet.Value or default_factory != NotSet.Value\n                required = _is_required(field_hint, not has_default)\n\n                fields[field.name] = Field(\n                    datatype=field_hint,\n                    required=required,\n                    default=None if not required and not has_default else default,\n                    default_factory=default_factory,\n                    flattened=_is_flat(field_hint, False),\n                )\n        else:\n            # This could mean that a base class is a dataclass but all of its members\n            # are overwritten by other fields.\n            pass\n\n        # Continue with the base classes.\n        for base in hint.bases or hint.type.__bases__:\n            base_hint = TypeHint(base, source=hint.type).evaluate().parameterize(parameter_map)\n            assert isinstance(base_hint, ClassTypeHint), f\"nani? {base_hint}\"\n            if dataclasses.is_dataclass(base_hint.type):\n                queue.append(base_hint)\n\n    return Schema(fields, t.cast(\"Constructor\", dataclass_type), dataclass_type)\n</code></pre>"},{"location":"api/databind.core/#databind.core.convert_to_schema","title":"convert_to_schema","text":"<pre><code>convert_to_schema(hint: TypeHint) -&gt; Schema\n</code></pre> <p>Convert the given type hint to a #Schema.</p> <p>The function delegates to #convert_dataclass_to_schema() or #convert_typed_dict_to_schema().</p> <p>Parameters:</p> Name Type Description Default <code>hint</code> <code>TypeHint</code> <p>The type hint to convert. If it is a #AnnotatedTypeHint hint, it will be unwrapped.</p> required <p>Raises:   ValueError: If the type hint is not supported.</p> Source code in <code>databind/core/schema.py</code> <pre><code>def convert_to_schema(hint: TypeHint) -&gt; Schema:\n    \"\"\"Convert the given type hint to a #Schema.\n\n    The function delegates to #convert_dataclass_to_schema() or #convert_typed_dict_to_schema().\n\n    Arguments:\n      hint: The type hint to convert. If it is a #AnnotatedTypeHint hint, it will be unwrapped.\n    Raises:\n      ValueError: If the type hint is not supported.\n    \"\"\"\n\n    assert isinstance(hint, TypeHint), hint\n    original_hint = hint\n\n    annotations = []\n    if isinstance(hint, AnnotatedTypeHint):\n        annotations = list(hint.metadata)\n        hint = hint[0]\n\n    if isinstance(hint, ClassTypeHint) and dataclasses.is_dataclass(hint.type):\n        schema = convert_dataclass_to_schema(hint)\n    elif isinstance(hint, ClassTypeHint) and is_typed_dict(hint.type):\n        # TODO(@NiklasRosenstein): Pass in the original TypeHint which will contain information about\n        #   TypeVar parametrization that is lost when we just pass the generic type.\n        schema = convert_typed_dict_to_schema(hint.type)\n    else:\n        raise ValueError(f\"cannot be converted to a schema (not a dataclass or TypedDict): {type_repr(original_hint)}\")\n\n    schema.annotations.extend(annotations)\n    return schema\n</code></pre>"},{"location":"api/databind.core/#databind.core.convert_typed_dict_to_schema","title":"convert_typed_dict_to_schema","text":"<pre><code>convert_typed_dict_to_schema(typed_dict: Union[TypedDictProtocol, Type[Any], TypeHint]) -&gt; Schema\n</code></pre> <p>Converts the definition of a #typing.TypedDict to a #Schema.</p> <p>Note</p> <p>This function will take into account default values assigned on the class-level of the typed dict (which is usually only relevant if the class-style declaration method was used, but default values can be assigned to the function-style declared type as well). Fields that have default values are considered not-required even if the declaration specifies them as required.</p> <p>Be aware that right-hand side values on #typing.TypedDict classes are not allowed by Mypy.</p> <p>Also note that #typing.TypedDict cannot be mixed with #typing.Generic, so keys with a generic type in the typed dict are not possible (state: 2022-03-17, Python 3.10.2).</p> <p>Todo</p> <p>Support understanding #typing.Required and #typing.NotRequired.</p> <p>Example:</p> <pre><code>from databind.core.schema import convert_typed_dict_to_schema, Schema, Field\nfrom typing import TypedDict\nfrom typeapi import TypeHint\nclass Movie(typing.TypedDict):\n  name: str\n  year: int = 0\nassert convert_typed_dict_to_schema(Movie) == Schema({\n  'name': Field(TypeHint(str)),\n  'year': Field(TypeHint(int), False, 0),\n}, Movie)\n</code></pre> Source code in <code>databind/core/schema.py</code> <pre><code>def convert_typed_dict_to_schema(typed_dict: t.Union[TypedDictProtocol, t.Type[t.Any], TypeHint]) -&gt; Schema:\n    \"\"\"Converts the definition of a #typing.TypedDict to a #Schema.\n\n    !!! note\n\n        This function will take into account default values assigned on the class-level of the typed dict (which is\n        usually only relevant if the class-style declaration method was used, but default values can be assigned to\n        the function-style declared type as well). Fields that have default values are considered not-required even\n        if the declaration specifies them as required.\n\n        Be aware that right-hand side values on #typing.TypedDict classes are not allowed by Mypy.\n\n        Also note that #typing.TypedDict cannot be mixed with #typing.Generic, so keys with a generic type in the\n        typed dict are not possible (state: 2022-03-17, Python 3.10.2).\n\n    !!! todo\n\n        Support understanding #typing.Required and #typing.NotRequired.\n\n    Example:\n\n    ```py\n    from databind.core.schema import convert_typed_dict_to_schema, Schema, Field\n    from typing import TypedDict\n    from typeapi import TypeHint\n    class Movie(typing.TypedDict):\n      name: str\n      year: int = 0\n    assert convert_typed_dict_to_schema(Movie) == Schema({\n      'name': Field(TypeHint(str)),\n      'year': Field(TypeHint(int), False, 0),\n    }, Movie)\n    ```\n    \"\"\"\n\n    if isinstance(typed_dict, TypeHint):\n        if not isinstance(typed_dict, ClassTypeHint):\n            raise TypeError(f\"expected ClassTypeHint, got {typed_dict}\")\n        typed_dict = typed_dict.type\n\n    assert is_typed_dict(typed_dict), typed_dict\n\n    eval_context = vars(sys.modules[typed_dict.__module__])\n\n    annotations = get_annotations(t.cast(type, typed_dict))\n    fields: t.Dict[str, Field] = {}\n    for key in typed_dict.__required_keys__ | typed_dict.__optional_keys__:\n        field_hint = TypeHint(annotations[key]).evaluate(eval_context)\n\n        has_default = hasattr(typed_dict, key)\n        required = _is_required(field_hint, not has_default)\n        fields[key] = Field(\n            datatype=field_hint,\n            required=required and typed_dict.__total__,\n            default=getattr(typed_dict, key) if has_default else None if not required else NotSet.Value,\n            flattened=_is_flat(field_hint, False),\n        )\n\n    return Schema(fields, t.cast(\"Constructor\", typed_dict), t.cast(type, typed_dict))\n</code></pre>"},{"location":"api/databind.core/#databind.core.format_context_trace","title":"format_context_trace","text":"<pre><code>format_context_trace(ctx: Context) -&gt; str\n</code></pre> <p>Formats a trace for the given context that is convenient to inspect in case of errors to understand where the context is pointing to in the payload that is being converted.</p> Source code in <code>databind/core/context.py</code> <pre><code>def format_context_trace(ctx: Context) -&gt; str:\n    \"\"\"Formats a trace for the given context that is convenient to inspect in case of errors to understand where the\n    context is pointing to in the payload that is being converted.\"\"\"\n\n    lines = []\n    prev_filename: t.Union[str, None] = None\n    for ctx in reversed(list(ctx.iter_hierarchy_up())):\n        # On the first context, or if the filename changed, we output the filename.\n        if ctx.location.filename != prev_filename and ctx.location.filename is not None:\n            lines.append(f'In \"{ctx.location.filename}\"')\n            prev_filename = ctx.location.filename\n\n        if ctx.key is Context.ROOT:\n            key = \"$\"\n        elif isinstance(ctx.key, str):\n            key = f\".{ctx.key}\"\n        elif isinstance(ctx.key, int):\n            key = f\"[{ctx.key}]\"\n        elif ctx.key is None:\n            key = \"^\"\n        else:\n            raise TypeError(f\"encountered unexpected type in Context.key: {ctx.key.__class__.__name__!r}\")\n\n        line = f\"  {key}: {ctx.datatype}\"\n        if ctx.location.line or ctx.location.column:\n            line = f\"{line} (at {ctx.location.line}:{ctx.location.column})\"\n\n        lines.append(line)\n\n    return \"\\n\".join(lines)\n</code></pre>"},{"location":"api/databind.core/#databind.core.get_annotation_setting","title":"get_annotation_setting","text":"<pre><code>get_annotation_setting(type_: TypeHint, setting_type: Type[T_Setting]) -&gt; T_Setting | None\n</code></pre> <p>Returns the first setting of the given setting_type from the given type hint from inspecting the metadata of the #AnnotatedTypeHint. Returns <code>None</code> if no such setting exists or if type_ is not an #AnnotatedTypeHint instance.</p> Source code in <code>databind/core/settings.py</code> <pre><code>def get_annotation_setting(type_: TypeHint, setting_type: t.Type[T_Setting]) -&gt; \"T_Setting | None\":\n    \"\"\"Returns the first setting of the given *setting_type* from the given type hint from inspecting the metadata\n    of the #AnnotatedTypeHint. Returns `None` if no such setting exists or if *type_* is not an #AnnotatedTypeHint\n    instance.\"\"\"\n\n    if isinstance(type_, AnnotatedTypeHint):\n        return get_highest_setting(s for s in type_.metadata if isinstance(s, setting_type))\n    return None\n</code></pre>"},{"location":"api/databind.core/#databind.core.get_class_setting","title":"get_class_setting","text":"<pre><code>get_class_setting(type_: type, setting_type: Type[T_ClassDecoratorSetting]) -&gt; T_ClassDecoratorSetting | None\n</code></pre> <p>Returns the first instance of the given setting_type on type_.</p> Source code in <code>databind/core/settings.py</code> <pre><code>def get_class_setting(type_: type, setting_type: t.Type[T_ClassDecoratorSetting]) -&gt; \"T_ClassDecoratorSetting | None\":\n    \"\"\"Returns the first instance of the given *setting_type* on *type_*.\"\"\"\n\n    return get_highest_setting(get_class_settings(type_, setting_type))\n</code></pre>"},{"location":"api/databind.core/#databind.core.get_class_settings","title":"get_class_settings","text":"<pre><code>get_class_settings(type_: type, setting_type: Type[T_ClassDecoratorSetting]) -&gt; Iterable[T_ClassDecoratorSetting]\n</code></pre> <p>Returns all matching settings on type_.</p> Source code in <code>databind/core/settings.py</code> <pre><code>def get_class_settings(\n    type_: type, setting_type: t.Type[T_ClassDecoratorSetting]\n) -&gt; t.Iterable[T_ClassDecoratorSetting]:\n    \"\"\"Returns all matching settings on *type_*.\"\"\"\n\n    for item in vars(type_).get(\"__databind_settings__\", []):\n        if isinstance(item, setting_type):\n            yield item\n</code></pre>"},{"location":"api/databind.core/#databind.core.get_fields_expanded","title":"get_fields_expanded","text":"<pre><code>get_fields_expanded(schema: Schema, convert_to_schema: Callable[[TypeHint], Schema] = convert_to_schema) -&gt; Dict[str, Dict[str, Field]]\n</code></pre> <p>Returns a dictionary that contains an entry for each flattened field in the schema, mapping to another dictionary that contains all fields expanded from the flattened field's sub-schema.</p> <p>Given a schema like the following example, this function returns something akin to the below.</p> <p>=== \"Schema\"</p> <pre><code>```\nSchema1:\n  a: int\n  b: Schema2, flattened=True\n\nSchema2:\n  c: str\n  d: Schema3, flattened=True\n\nSchema3:\n  e: int\n```\n</code></pre> <p>=== \"Result\"</p> <pre><code>```py\n{\n  \"b\": {\n    \"c\": Field(str),\n    \"e\": Field(int)\n  }\n}\n</code></pre> <p>Arguments:   schema: The schema to compile the expanded fields for.   convert_to_schema: A function that accepts a #TypeHint and converts it to a schema.     Defaults to the #convert_to_schema() function.</p> <p>Note</p> <p>The top-level dictionary returned by this function contains only those fields that are flattened and should be \"composed\" of other fields.</p> <p>```</p> Source code in <code>databind/core/schema.py</code> <pre><code>def get_fields_expanded(\n    schema: Schema,\n    convert_to_schema: t.Callable[[TypeHint], Schema] = convert_to_schema,\n) -&gt; t.Dict[str, t.Dict[str, Field]]:\n    \"\"\"Returns a dictionary that contains an entry for each flattened field in the schema, mapping to another\n    dictionary that contains _all_ fields expanded from the flattened field's sub-schema.\n\n    Given a schema like the following example, this function returns something akin to the below.\n\n    === \"Schema\"\n\n        ```\n        Schema1:\n          a: int\n          b: Schema2, flattened=True\n\n        Schema2:\n          c: str\n          d: Schema3, flattened=True\n\n        Schema3:\n          e: int\n        ```\n\n    === \"Result\"\n\n        ```py\n        {\n          \"b\": {\n            \"c\": Field(str),\n            \"e\": Field(int)\n          }\n        }\n\n    Arguments:\n      schema: The schema to compile the expanded fields for.\n      convert_to_schema: A function that accepts a #TypeHint and converts it to a schema.\n        Defaults to the #convert_to_schema() function.\n\n    !!! note\n\n        The top-level dictionary returned by this function contains _only_ those fields that are\n        flattened and should be \"composed\" of other fields.\n    ```\n    \"\"\"\n\n    result = {}\n    for field_name, field in schema.fields.items():\n        if field.flattened:\n            field_schema = convert_to_schema(field.datatype)\n            result[field_name] = {\n                **{k: v for k, v in field_schema.fields.items() if not v.flattened},\n                **{k: v for sf in get_fields_expanded(field_schema).values() for k, v in sf.items()},\n            }\n            for sub_field_name in result[field_name]:\n                if sub_field_name in schema.fields and sub_field_name != field_name:\n                    raise RuntimeError(f\"field {sub_field_name!r} occurs multiple times\")\n    return result\n</code></pre>"},{"location":"api/databind.core/#databind.core.get_highest_setting","title":"get_highest_setting","text":"<pre><code>get_highest_setting(settings: Iterable[T_Setting]) -&gt; T_Setting | None\n</code></pre> <p>Return the first, highest setting of settings.</p> Source code in <code>databind/core/settings.py</code> <pre><code>def get_highest_setting(settings: t.Iterable[T_Setting]) -&gt; \"T_Setting | None\":\n    \"\"\"Return the first, highest setting of *settings*.\"\"\"\n\n    try:\n        return max(settings, key=lambda s: s.priority)\n    except ValueError:\n        return None\n</code></pre>"},{"location":"api/databind.json/","title":"databind.json","text":""},{"location":"api/databind.json/#databind.json","title":"databind.json","text":"<p>The #databind.json package implements the capabilities to bind JSON payloads to objects and the reverse.</p>"},{"location":"api/databind.json/#databind.json.JsonConverter","title":"JsonConverter","text":"<p>             Bases: <code>ClassDecoratorSetting</code></p> <p>Use this setting to decorate a class or to annotate a type hint to inform the JSON module to use the specified convert when deserialize the type instead of any converter that would otherwise match the type.</p> <p>Example:</p> <pre><code>from databind.json.settings import JsonConverter\n\n\n\nclass MyCustomConverter(Converter):\n    def __init__(self, direction: Direction) -&gt; None:\n        self.direction = direction\n    def convert(self, ctx: Context) -&gt; Any:\n        ...\n\n@JsonConverter.using_classmethods(serialize=\"__str__\", deserialize=\"of\")\nclass MyCustomType:\n\n    def __str__(self) -&gt; str:\n        ...\n\n    @staticmethod\n    def of(s: str) -&gt; MyCustomType:\n        ...\n</code></pre> <p>The same override can also be achieved by attaching the setting to an <code>Annotated</code> type hint:</p> <pre><code>Annotated[MyCustomType, JsonConverter(MyCustomConverter)]\n</code></pre> Source code in <code>databind/json/settings.py</code> <pre><code>class JsonConverter(ClassDecoratorSetting):\n    \"\"\"Use this setting to decorate a class or to annotate a type hint to inform the JSON module to use the\n    specified convert when deserialize the type instead of any converter that would otherwise match the type.\n\n    Example:\n\n    ```py\n    from databind.json.settings import JsonConverter\n\n\n\n    class MyCustomConverter(Converter):\n        def __init__(self, direction: Direction) -&gt; None:\n            self.direction = direction\n        def convert(self, ctx: Context) -&gt; Any:\n            ...\n\n    @JsonConverter.using_classmethods(serialize=\"__str__\", deserialize=\"of\")\n    class MyCustomType:\n\n        def __str__(self) -&gt; str:\n            ...\n\n        @staticmethod\n        def of(s: str) -&gt; MyCustomType:\n            ...\n    ```\n\n    The same override can also be achieved by attaching the setting to an `Annotated` type hint:\n\n\n    ```py\n    Annotated[MyCustomType, JsonConverter(MyCustomConverter)]\n    ```\n    \"\"\"\n\n    supplier: ConverterSupplier\n\n    def __init__(self, supplier: t.Union[ConverterSupplier, Converter]) -&gt; None:\n        super().__init__()\n        if isinstance(supplier, Converter):\n            self.supplier = lambda: supplier\n        else:\n            self.supplier = supplier\n\n    @staticmethod\n    def using_classmethods(\n        serialized_type: t.Union[t.Type[t.Any], t.Tuple[t.Type[t.Any], ...], None] = None,\n        *,\n        serialize: \"str | None\" = None,\n        deserialize: \"str | None\" = None\n    ) -&gt; \"JsonConverter\":\n        return JsonConverter(\n            DelegateToClassmethodConverter(serialized_type, serialize=serialize, deserialize=deserialize)\n        )\n</code></pre>"},{"location":"api/databind.json/#databind.json.JsonModule","title":"JsonModule","text":"<p>             Bases: <code>Module</code></p> <p>The JSON module combines all converters provided by the #databind.json package in one usable module. The direction in which the converters should convert must be specified with the direction argument. Alternatively, use one of the convenience static methods #serializing() and #deserializing().</p> Source code in <code>databind/json/module.py</code> <pre><code>class JsonModule(Module):\n    \"\"\"The JSON module combines all converters provided by the #databind.json package in one usable module. The\n    direction in which the converters should convert must be specified with the *direction* argument. Alternatively,\n    use one of the convenience static methods #serializing() and #deserializing().\"\"\"\n\n    def __init__(self) -&gt; None:\n        super().__init__(__name__ + \".JsonModule\")\n\n        import pathlib\n        import uuid\n\n        from nr.date import duration\n\n        from databind.json.converters import (\n            AnyConverter,\n            CollectionConverter,\n            DatetimeConverter,\n            DecimalConverter,\n            EnumConverter,\n            LiteralConverter,\n            MappingConverter,\n            OptionalConverter,\n            PlainDatatypeConverter,\n            SchemaConverter,\n            StringifyConverter,\n            UnionConverter,\n        )\n\n        self.register(AnyConverter())\n        self.register(CollectionConverter())\n        self.register(DatetimeConverter())\n        self.register(DecimalConverter())\n        self.register(EnumConverter())\n        self.register(MappingConverter())\n        self.register(OptionalConverter())\n        self.register(PlainDatatypeConverter())\n        self.register(UnionConverter())\n        self.register(SchemaConverter())\n        self.register(StringifyConverter(uuid.UUID, name=\"JsonModule:uuid.UUID\"), first=True)\n\n        # NOTE(NiklasRosenstein): It is important that we have the converter for `Path` appear before the converter\n        #       for `PurePath` for the `issubclass()` checks in the converter to match appropriately due to Liskov\n        #       substition principle (otherwise you would end up deserializing a `Path` field as a `PurePath` but\n        #       then actually serialize it as a `Path` which causes an error, \"expected Path, got PurePath\").\n        self.register(StringifyConverter(pathlib.PurePath, name=\"JsonModule:pathlib.PurePath\"), first=True)\n        self.register(StringifyConverter(pathlib.Path, name=\"JsonModule:pathlib.Path\"), first=True)\n        self.register(StringifyConverter(duration, duration.parse, name=\"JsonModule:nr.date.duration\"), first=True)\n        self.register(LiteralConverter())\n\n        self.register(JsonConverterSupport(), first=True)\n</code></pre>"},{"location":"api/databind.json/#databind.json.JsonModule.__init__","title":"__init__","text":"<pre><code>__init__() -&gt; None\n</code></pre> Source code in <code>databind/json/module.py</code> <pre><code>def __init__(self) -&gt; None:\n    super().__init__(__name__ + \".JsonModule\")\n\n    import pathlib\n    import uuid\n\n    from nr.date import duration\n\n    from databind.json.converters import (\n        AnyConverter,\n        CollectionConverter,\n        DatetimeConverter,\n        DecimalConverter,\n        EnumConverter,\n        LiteralConverter,\n        MappingConverter,\n        OptionalConverter,\n        PlainDatatypeConverter,\n        SchemaConverter,\n        StringifyConverter,\n        UnionConverter,\n    )\n\n    self.register(AnyConverter())\n    self.register(CollectionConverter())\n    self.register(DatetimeConverter())\n    self.register(DecimalConverter())\n    self.register(EnumConverter())\n    self.register(MappingConverter())\n    self.register(OptionalConverter())\n    self.register(PlainDatatypeConverter())\n    self.register(UnionConverter())\n    self.register(SchemaConverter())\n    self.register(StringifyConverter(uuid.UUID, name=\"JsonModule:uuid.UUID\"), first=True)\n\n    # NOTE(NiklasRosenstein): It is important that we have the converter for `Path` appear before the converter\n    #       for `PurePath` for the `issubclass()` checks in the converter to match appropriately due to Liskov\n    #       substition principle (otherwise you would end up deserializing a `Path` field as a `PurePath` but\n    #       then actually serialize it as a `Path` which causes an error, \"expected Path, got PurePath\").\n    self.register(StringifyConverter(pathlib.PurePath, name=\"JsonModule:pathlib.PurePath\"), first=True)\n    self.register(StringifyConverter(pathlib.Path, name=\"JsonModule:pathlib.Path\"), first=True)\n    self.register(StringifyConverter(duration, duration.parse, name=\"JsonModule:nr.date.duration\"), first=True)\n    self.register(LiteralConverter())\n\n    self.register(JsonConverterSupport(), first=True)\n</code></pre>"},{"location":"examples/config-serde/","title":"Configuration Serde","text":"<p>A common use case is to describe the configuration for an application as dataclasses, then deserialize it from a JSON, YAMl or TOML file.</p> <pre><code>from __future__ import annotations\nimport databind.json\nimport dataclasses\nimport tomlib\nfrom pathlib import Path\n\n@dataclasses.dataclass\nclass ServerConfig:\n    host: str\n    port: int = 8080\n\n@dataclasses.dataclass\nclass MainConfig:\n    server: ServerConfig\n\n    @staticmethod\n    def load(path: Path | str) -&gt; MainConfig:\n        data = tomlib.loads(Path(path).read_text())\n        return databind.json.load(data, MainConfig, filename=path)\n\nconfig = MainConfig.load_toml(\"config.toml\")\n</code></pre> <p>An example config TOML file that can be parsed with the above configuration:</p> <pre><code>[server]\nhost = \"localhost\"\nport = 8080\n</code></pre> <p>Note that any extra keys that are not expected per the schema will raise a <code>databind.core.converter.ConversionError</code>.</p> <p>Danger</p> <p>Databind uses Python runtime type annotation introspection using the <code>typeapi</code> package. This requires that all type annotations that databind comes in contact with must be valid expressions in the current Python version, even if <code>from __future__ import annotations</code> is used.</p> <p>This means if your code needs to be compatible with Python versions lower than 3.10 or 3.9 that you can not use the new type union syntax (<code>a | b</code>) or built-in generic aliases (such as <code>t.List[int]</code>) and need to continue to use <code>typing.Union</code>, <code>typing.Optional</code> and <code>typing.List</code>, etc.</p>"},{"location":"examples/unions/","title":"Defining Unions","text":""},{"location":"examples/unions/#dynamic-unions-with-union-mappers","title":"Dynamic unions with union mappers","text":"<p>Todo</p>"},{"location":"examples/unions/#using-typingliteral-as-discriminator","title":"Using <code>typing.Literal</code> as discriminator","text":"<p>When unions are deserialized, they can be accommodated by a \"union mapper\" to identify based on a value in the payload how that payload can be deserialized.</p> <p>However, you can also use <code>Literal</code> type hints on dataca,sses in combination with naive union types. The <code>Literal</code> will fail to deserialize if the value in the payload does not match with the literal value, and naive union types will try all types in the union in order and return the first successfully deserialized type.</p> <p>Note</p> <p>Arguably this is rather inefficient; a better implementation would be to prioritize checking values of literal fields first so we don't need to attempt to deserialize the rest if there's no match.</p> <pre><code># cat &lt;&lt;EOF | python -\nimport dataclasses\nfrom databind.json import load\nfrom typing import Literal\n\n@dataclasses.dataclass\nclass AwsMachine:\n  region: str\n  name: str\n  instance_id: str\n  provider: Literal[\"aws\"] = \"aws\"\n\n@dataclasses.dataclass\nclass AzureMachine:\n  resource_group: str\n  name: str\n  provider: Literal[\"azure\"] = \"azure\"\n\nMachine = AwsMachine | AzureMachine\n\npayload = {\n    \"provider\": \"azure\",\n    \"resource_group\": \"foo\",\n    \"name\": \"bar\",\n}\nassert load(payload, Machine) == AzureMachine(\"foo\", \"bar\")\n</code></pre>"},{"location":"examples/unknown-keys/","title":"Handling unknown keys during deserialization","text":"<p>If you would like to permit extra keys to to be present in a payload that is being deserialized without raising a <code>databind.core.converter.ConversionError</code>, you can use the <code>databind.core.settings.ExtraKeys</code> setting to annotate a <code>@dataclass</code>, an annotation or specify it globally to allow extra keys anywhere.</p> <p>When using this setting, you can also record any unexpected keys so you can report them after the deserialization.</p>"},{"location":"examples/unknown-keys/#allowing-extra-keys-on-a-dataclass","title":"Allowing extra keys on a dataclass","text":"<pre><code># cat &lt;&lt;EOF | python -\nfrom dataclasses import dataclass\nfrom databind.core import ExtraKeys\nfrom databind.json import load\n\n@ExtraKeys()\n@dataclass\nclass MyClass:\n    a: int\n\nassert load({\"a\": 42, \"b\": \"ignored\"}, MyClass) == MyClass(42)\n</code></pre> <p>Note</p> <p>The <code>ExtraKeys</code> setting does not apply transitively to the members of the dataclass.</p>"},{"location":"examples/unknown-keys/#allowing-extra-keys-on-a-dataclass-member","title":"Allowing extra keys on a dataclass member","text":"<pre><code># cat &lt;&lt;EOF | python -\nfrom dataclasses import dataclass\nfrom databind.core import ExtraKeys\nfrom databind.json import load\nfrom typing_extensions import Annotated\n\n@dataclass\nclass Sub:\n    a: int\n\n@dataclass\nclass Main:\n    sub: Annotated[Sub, ExtraKeys()]\n\nassert load({\"sub\": {\"a\": 42, \"b\": \"ignored\"}}, Main) == Main(Sub(42))\n\n# However this:\n\nload({\"sub\": {\"a\": 42}, \"b\": \"not ignored!\"}, Main)\n\n# Gives:\n# databind.core.converter.ConversionError: encountered extra keys: {'b'}\n#  Conversion trace:\n#     $: Type(__main__.Main)\n</code></pre>"},{"location":"examples/unknown-keys/#allowing-extra-keys-everywhere","title":"Allowing extra keys everywhere","text":"<p>Providing the <code>ExtraKeys()</code> setting to the <code>settings</code> of a deserialization process will enable it for all schemas, except for those that have a different setting \"closer by\" (you can use <code>ExtraKeys(False)</code> to explicitly not permit extra keys).</p> <pre><code># cat &lt;&lt;EOF | python -\nfrom dataclasses import dataclass\nfrom databind.core import ExtraKeys\nfrom databind.json import load\n\n@dataclass\nclass MyClass:\n    a: int\n\nassert load({\"a\": 42, \"b\": \"ignore\"}, MyClass, settings=[ExtraKeys()]) == MyClass(42)\n</code></pre>"},{"location":"examples/unknown-keys/#recording-extra-keys","title":"Recording extra keys","text":"<p>You can also record which extra keys have been encountered to report. This is common if you want to allow but warn about unused keys in a payload.</p> <pre><code># cat &lt;&lt;EOF | python -\nfrom dataclasses import dataclass\nfrom databind.core import format_context_trace, ExtraKeys\nfrom databind.json import load\n\n@dataclass\nclass MyClass:\n    a: int\n\nrecorded = []\nassert load({\"a\": 42, \"b\": \"ignore\"}, MyClass, settings=[ExtraKeys(recorder=lambda ctx, keys: recorded.append((ctx, keys)))]) == MyClass(42)\n\nfor ctx, keys in recorded:\n    print(\"warning: unused keys\", keys, \"at\")\n    print(format_context_trace(ctx))\n\n# Gives:\n#\n# warning: unused keys {'b'} at\n#   $: Type(__main__.MyClass)\n</code></pre>"}]}